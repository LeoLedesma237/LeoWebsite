---
title: "ONR Day Labeling"
author: "Leandro Ledesma"
output: html_document
---

### Universal block code settings

```{r universal block code setting}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(comment = NULL)
```

### Load in the data manipulation packages first

```{r load in packages, message= FALSE, warning = FALSE}
# Load in packages
library(tidyverse)
library(readxl)
library(gdata) # Use startsWith function
library(base) #subset strings
library(scales)
library(rio)
library(purrr)
```


### Last day this code was ran

```{r last day the code was ran}

paste("This code was last ran on:", Sys.Date())

```

### Create ID's with leading zeroes

```{r first block}
# Create an empty character vector to store ID numbers
ID.numbers <- character(999)

# Use sprintf to format the values with leading zeros so it creates a vector with zeroes in fron of each number smaller than 100
for (i in 1:999) {
  ID.numbers[i] <- sprintf("%03d", i)
}

# Check to see if the zeroes were added
head(ID.numbers,99)

```


### Load in the data

These next few sections are a bit complex. ONR behavioral data is saved locally on two separate computers (UH-ONR and UH-ONR2). This is because we are using two rooms for data collection, each with their own VR systems. Every day around 3:00 AM, these locally saved data are transfered to a secure server and saved in separate folders. Inside these directories, ID named folders (ex: 001 or 015) contain CSV files representing the performance during the VR tasks. Each CSV corresponds to a GnG or an Nback task completed on one of the four testing days. 

### Obtaining pathways to participant's behavioral data

This first chunk of code is going into both directories on the server and recording the pathways of participants that have behavioral data saved. 

```{r obtaining pathways with behavioral data for each subject, warning = FALSE}
# set working directory for ONR computer 1
setwd("M:/VR_CSVs/UH-ONR")

# let's get the names of all the files in the folder
file.names.UH_ONR <- list.files()

# set working directory for ONR computer 1
setwd("M:/VR_CSVs/UH-ONR2")

# let's get the names of all the files in the folder
file.names.UH_ONR2 <- list.files()

# Obtain the intersected IDs from both computers
intersect.IDs.UH_ONR <- intersect(file.names.UH_ONR,ID.numbers)
intersect.IDs.UH_ONR2 <- intersect(file.names.UH_ONR2,ID.numbers)

# Create two pathways using the intersected IDs
pathway.UH_ONR <- paste("M:/VR_CSVs/UH-ONR/",intersect.IDs.UH_ONR,"/", sep="")
pathway.UH_ONR2 <- paste("M:/VR_CSVs/UH-ONR2/",intersect.IDs.UH_ONR2,"/", sep="")

```

### Obtaining each CSV file name for computer 1

This next chunk of code is using the pathways from above to record the names and pathways of each CSV file in Computer 1 and saving them as a data frame. 

```{r obtain pathway csvs and computer data frame for computer 1}

# Create a for loop to go into each pathway of a subject's ID folder and extract the names of CSV's present there
# Do this for both pathways
# Computer 1
CSVs.UH_ONR <- list()

for(ii in 1:length(pathway.UH_ONR)) {
  #ii = 1
  # Changes the working directory to each pathway
  setwd(pathway.UH_ONR[[ii]])
  
  # Obtain the CSVs for the folder
  CSVs.current <- list.files()
  
  # Create a vector for the current ID and computer number (Repeat it by the number of CSVs present)
  current.ID <- rep(intersect.IDs.UH_ONR[ii], length(CSVs.current))
  current.pathway <- rep(pathway.UH_ONR[ii], length(CSVs.current))
  current.computer <- rep("Computer 1", length(CSVs.current))
  
  # Create a data frame including the ID, the pathway, CSV, and the computer number
  UH_ONR.df <- data.frame(ID = current.ID,
                          Pathway = current.pathway,
                          CSVs = CSVs.current,
                          Computer = current.computer) 
  
  # Extracts all the names of the CSVs located in that pathway + it's pathway
  CSVs.UH_ONR[[ii]] <- UH_ONR.df
}

CSVs.UH_ONR <- CSVs.UH_ONR %>%
  do.call(rbind,.) %>%
  data.frame()

```

### Obtaining each CSV file name for computer 2

This next chunk of code does the same as above except for the files in computer 2.  

```{r obtain pathway csvs and computer data frame for computer 2}

# Create a for loop to go into each pathway of a subject's ID folder and extract the names of CSV's present there
# Do this for both pathways
# Computer 2
CSVs.UH_ONR2 <- list()

for(ii in 1:length(pathway.UH_ONR2)) {
  #ii = 1
  # Changes the working directory to each pathway
  setwd(pathway.UH_ONR2[[ii]])
  
  # Obtain the CSVs for the folder
  CSVs.current <- list.files()
  
  # Create a vector for the current ID and computer number (Repeat it by the number of CSVs present)
  current.ID <- rep(intersect.IDs.UH_ONR2[ii], length(CSVs.current))
  current.pathway <- rep(pathway.UH_ONR2[ii], length(CSVs.current))
  current.computer <- rep("Computer 2", length(CSVs.current))
  
  # Create a data frame including the ID, the pathway, CSV, and the computer number
  UH_ONR.df <- data.frame(ID = current.ID,
                          Pathway = current.pathway,
                          CSVs = CSVs.current,
                          Computer = current.computer) 
  
  # Extracts all the names of the CSVs located in that pathway + it's pathway
  CSVs.UH_ONR2[[ii]] <- UH_ONR.df
}

CSVs.UH_ONR2 <- CSVs.UH_ONR2 %>%
  do.call(rbind,.) %>%
  data.frame()

```


### Removing redundant CSVs from computer 2

Unfortunately, we have some redundant files from early data recording in the project. Some files saved in Computer 2 are identical to files saved in Computer 1. We want to identify these files and associate them with only one pathway before we start to read them in. This will make the computing process more efficient.

```{r identifying duplicates and removing them}
# Identify CSVs in Computer 2 that are not in Computer 1 (save non duplicate CSVs)
nonDuplicate.CSVs <- setdiff(CSVs.UH_ONR2$CSVs, CSVs.UH_ONR$CSVs)

# Overwrite the Computer 2 data frame with one containing only CSVs that are not in Computer 1
CSVs.UH_ONR2 <- CSVs.UH_ONR2 %>%
  filter(CSVs %in% nonDuplicate.CSVs)

```

### Identifying complete subjects from VR data

The logic is as follows. There are four testing days and each day two CSV files are saved- one for GnG and the other for the Nback. On Day 0 (practice day) a 30 minute practice session CSV is saved for both tasks. On day 1 the baseline CSVs are saved. On day 2 the intense exercise CSVs are saved. And lastly, on day 3 the sleep deprivation CSVs are saved. Thus, a subject that completed all testing days will have 8 CSVs. 

We will be merging the data frames from both computers created in the previous scripts and extracting the ID numbers that have 8 CSVs saved. We will then use this information to create a new variable indicating whether the subject is complete or not. 

```{r}
# Merge the datasets from above
CSVs.merged.UH_ONR <- CSVs.UH_ONR %>%
  rbind(CSVs.UH_ONR2)

# Total unique ID's from all subjects that have a VR session saved
paste("There is at least one CSV file saved from", length(unique(CSVs.merged.UH_ONR$ID)), "participants", sep= " ")

# IDs that have 8 file names
completed.IDs <- CSVs.merged.UH_ONR %>%
  group_by(ID) %>%
  count() %>%
  filter(n == 8) %>%
  select(ID) %>%
  unlist() %>% unname()

# Complete ID's and their pathways 
CSVs.merged.UH_ONR <- CSVs.merged.UH_ONR %>%
  mutate(Status = ifelse(ID %in% completed.IDs, "Complete", "Incomplete"))

# Total unique ID's from all subjects that have all VR sessions accounted for
paste("All VR sessions accounted for", length(completed.IDs), "participants", sep= " ")

```

### Read in the files

We will now read in the files and save them into a list. This takes about 30 seconds. Additionally, as each file is being read, a new variable called computer will be added that indicates if the data was recorded in Computer 1 or in Computer 2. 

```{r reading in the files}
# Read in the files
all.CSVs <- list()

for(ii in 1:nrow(CSVs.merged.UH_ONR)) {
  
  # Current file name and its pathway 
  current.csv <- paste(CSVs.merged.UH_ONR$Pathway[ii],  CSVs.merged.UH_ONR$CSVs[ii], sep="")
    
  # Read in and save the current CSV in a list
  read.csv <- read.csv(current.csv)
  
  # Mutate the csv to include which computer it came from
  read.csv$Computer <- rep(CSVs.merged.UH_ONR$Computer[ii], times = nrow(read.csv))
  
  # Save the mutated CSV
  all.CSVs[[ii]] <- read.csv
  
  # Name the list by the ID and CSV
  names(all.CSVs)[[ii]] <- paste(CSVs.merged.UH_ONR$ID[ii],CSVs.merged.UH_ONR$CSVs[ii])
}

# Check to see that the above code worked
paste("There are", length(all.CSVs),"CSV files that were read in", sep =" ")

# Half of the CSVs, the ones for GnG have the following dimensions
dim(all.CSVs[[8]])

# The other half of the CSVs, the ones for Nback each have the following dimensions
dim(all.CSVs[[9]])

```
### Using the map function

We will now be creating a data frame where the column tibble will have data over the VR CSV files for each person. We will use this new data frame to extract data from the first row of each CSV file- just so we can be sure we know exactly what we are looking at. 

#```{r Using the map function}
# Create a new data frame that will contain all CSV information
all.data <- data.frame(file.num = 1:length(all.CSVs))

# Use the map function to make a variable called tibble, where each row contains the full data from the VR CSV
all.data$tibbles <- map(all.CSVs, as_tibble)

# Create for loops that extract information from the first row of each data frame in the tibbles variable
# This will include ID, day of testing, task type (GnG/Nback)

UserID <- list()
StartDate <- list()
Task_Type_list <- list()

for(ii in 1:nrow(all.data)) {

Current_dataset <- all.data$tibbles[[ii]]
UserID[ii] <- Current_dataset$UserID[1]
Date_long <- Current_dataset$StartDate[1]
StartDate[ii] <- substr(Date_long,1,10)

Task_type <- Current_dataset$BlockID[1]

if(substr(Task_type,1,1) == "G") {
  Task_Type_list[ii] <- "Go/NoGo"

} else if(substr(Task_type,1,1) == "N") {
  Task_Type_list[ii] <- "N-back"
  
}

}

all.data$UserID <- unlist(UserID)
all.data$StartDate <- unlist(StartDate)
all.data$Task_Type <- unlist(Task_Type_list)
all.data$User_ID_check <- UserID_VR_Room$UserID
all.data$VR_Room <- UserID_VR_Room$VR_Room


# Create for loops that go into each one of these data frames and retrieve information of interest only from the first row
# This will include UserID and StartDate

head(all.data)

#```





# Minor data cleaning
ID_13_fix <- function(ID) {
  if(ID == "13") {
    return("013")
  } else {
    return(ID)
  }
}

# Go into each data frame that is mapped into the all.data and identify UserID that is equal to 13.
# For those files that are (Go/NoGo and N-back), change all of the rows in UserID to 013

tibbles <- list()

for(ii in 1:nrow(all.data)) {
  Current_UserID <- all.data$UserID[ii]
  Current_tibble <- all.data$tibbles[[ii]]
  
  if(Current_UserID == "13") {
  
    Current_tibble$UserID   <- sapply(Current_tibble$UserID,ID_13_fix)
      
    tibbles[[ii]] <- Current_tibble
    
  } else {
    
    tibbles[[ii]] <- Current_tibble
  }
  
}



all.data$tibbles <- map(tibbles,as_tibble)

# Now change it on the actual main data UserID
all.data$UserID <- sapply(all.data$UserID, ID_13_fix)



############ Introducing Dates #################

# Load in ONR Visitor Log Data
Visitor_Log_Full <- read_excel("~/ONR/Visitor_log/Visiting_Log_must_manually_update.xlsx")

# Create dataframe with variables that are needed
Visitor_Log <- data.frame(ID = Visitor_Log_Full$ID,
                          Day0 = Visitor_Log_Full$`Day 0 Date`,
                          Day1 = Visitor_Log_Full$`Day 1 Date`,
                          Day2 = Visitor_Log_Full$`Day 2 Date`,
                          Day3 = Visitor_Log_Full$`Day 3 Date`) %>% as_tibble()

# Change the variables into characters
Visitor_Log$Day0 <- as.character(Visitor_Log$Day0)
Visitor_Log$Day1 <- as.character(Visitor_Log$Day1)
Visitor_Log$Day2 <- as.character(Visitor_Log$Day2)
Visitor_Log$Day3 <- as.character(Visitor_Log$Day3)

# Replace all NAs to "0000-00-00" so code below can work
Visitor_Log[is.na(Visitor_Log)] <- "0000-00-00"

# Use dates from Visitor Log to determine which day we have data for in VR tasks
unique(all.data$StartDate)

# CODE WILL BREAK IF WE HAVE DATA FOR AN ID (IN VR) THAT IS NOT PRESENT IN VISITOR LOG

Day <- list()
row_num <- list()


for(ii in 1:nrow(all.data)) {
  Current_ID_row <- all.data$UserID[ii]  
  Current_date_row <- all.data$StartDate[ii]

  Visitor_Log_row <- Visitor_Log %>%
    filter(ID == Current_ID_row)
  
  row_num[ii] <- ii
  
  if(Current_date_row == Visitor_Log_row$Day0[1]) {
    Day[ii] <- "Day0"
    
  } else if(Current_date_row == Visitor_Log_row$Day1[1]) {
    Day[ii] <- "Rest"
    
  } else if(Current_date_row == Visitor_Log_row$Day2[1]) {
    Day[ii] <- "Exercise"
    
  } else if(Current_date_row == Visitor_Log_row$Day3[1]) {
    Day[ii] <- "No Sleep"
    
  } else {
    Day[ii] <- "Error"
    
  }
  
}


# Add which day belongs to which dataset
all.data$Day <- unlist(Day)


# Add the days inside the house
tibbles <- list()

for(ii in 1:nrow(all.data)) {
  
  Current_Tibble <- all.data$tibbles[[ii]]
  Current_Tibble$Day <- rep(all.data$Day[ii],nrow(Current_Tibble))
  Current_Tibble <- Current_Tibble %>% select(Day, everything())
  tibbles[[ii]] <- Current_Tibble
  
}

all.data$tibbles_withDay <- map(tibbles,as_tibble)


# Substr the StartDate
tibbles <- list()

for(ii in 1:nrow(all.data)) {
  
  Current_Tibble <- all.data$tibbles_withDay[[ii]]
  Current_Tibble$StartDate <- substr(rep(all.data$StartDate[1],nrow(Current_Tibble)),1,10)
  Current_Tibble$StartDate <- as.character(Current_Tibble$StartDate)
  Current_Tibble <- Current_Tibble %>% select(Day, everything())
  tibbles[[ii]] <- Current_Tibble
  
}

all.data$tibbles_withDay <- map(tibbles,as_tibble)



# Add VR room variable to tibbles
tibbles <- list()

for(ii in 1:nrow(all.data)) {
  
  Current_Tibble <- all.data$tibbles_withDay[[ii]]
  Current_Tibble$VR_Room  <- substr(rep(all.data$VR_Room[ii],nrow(Current_Tibble)),1,10)
  Current_Tibble$VR_Room  <- as.character(Current_Tibble$VR_Room )
  Current_Tibble <- Current_Tibble %>% select(Day, everything())
  tibbles[[ii]] <- Current_Tibble
  
}

all.data$tibbles_withDay_VR_Room <- map(tibbles,as_tibble)



# Split the data based on their task
All_GnG <- all.data %>%
  filter(Task_Type %in%  "Go/NoGo")

All_Nback <- all.data %>%
  filter(Task_Type %in%  "N-back")

# Combine all the tibbles into one data frame
All_GnG_tibbles <- do.call(rbind, as.list(All_GnG$tibbles_withDay_VR_Room))
All_Nback_tibbles <- do.call(rbind, as.list(All_Nback$tibbles_withDay_VR_Room))




# Quality control
table(All_GnG_tibbles$Day)
table(All_Nback_tibbles$Day)

table(All_GnG_tibbles$VR_Room)
table(All_Nback_tibbles$VR_Room)


# IDs with errors?
All_GnG_tibbles %>% filter(Day == "Error") %>% select(UserID) %>% unique()
All_Nback_tibbles %>% filter(Day == "Error") %>% select(UserID) %>% unique()


# export data
# set working directory
setwd("~/ONR/GnG_and_Nback_behavioral_data_preprocessing/Processed Data")

#export the files
export(All_GnG_tibbles, "GnG_Performance.xlsx")
export(All_Nback_tibbles, "Nback_Performance.xlsx")