---
title: "ONR Day Labeling"
author: "Leandro Ledesma"
output: html_document
---

### Universal block code settings

```{r universal block code setting}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(comment = NULL)
```

### Load in the data manipulation packages first

```{r load in packages, message= FALSE, warning = FALSE}
# Load in packages
library(tidyverse)
library(readxl)
library(gdata) # Use startsWith function
library(base) #subset strings
library(scales)
library(rio)
library(purrr)
```


### Last day this code was ran

```{r last day the code was ran}

paste("This code was last ran on:", Sys.Date())

```

### Create ID's with leading zeroes

```{r first block}
# Create an empty character vector to store ID numbers
ID.numbers <- character(999)

# Use sprintf to format the values with leading zeros so it creates a vector with zeroes in fron of each number smaller than 100
for (i in 1:999) {
  ID.numbers[i] <- sprintf("%03d", i)
}

# Check to see if the zeroes were added
head(ID.numbers,99)

```


### Load in the data

These next few sections are a bit complex. ONR behavioral data is saved locally on two separate computers (UH-ONR and UH-ONR2). This is because we are using two rooms for data collection, each with their own VR systems. Every day around 3:00 AM, these locally saved data are transfered to a secure server and saved in separate folders. Inside these directories, ID named folders (ex: 001 or 015) contain CSV files representing the performance during the VR tasks. Each CSV corresponds to a GnG or an Nback task completed on one of the four testing days. 

### Obtaining pathways to participant's behavioral data

This first chunk of code is going into both directories on the server and recording the pathways of participants that have behavioral data saved. 

```{r obtaining pathways with behavioral data for each subject, warning = FALSE}
# set working directory for ONR computer 1
setwd("M:/VR_CSVs/UH-ONR")

# let's get the names of all the files in the folder
file.names.UH_ONR <- list.files()

# set working directory for ONR computer 1
setwd("M:/VR_CSVs/UH-ONR2")

# let's get the names of all the files in the folder
file.names.UH_ONR2 <- list.files()

# Obtain the intersected IDs from both computers
intersect.IDs.UH_ONR <- intersect(file.names.UH_ONR,ID.numbers)
intersect.IDs.UH_ONR2 <- intersect(file.names.UH_ONR2,ID.numbers)

# Create two pathways using the intersected IDs
pathway.UH_ONR <- paste("M:/VR_CSVs/UH-ONR/",intersect.IDs.UH_ONR,"/", sep="")
pathway.UH_ONR2 <- paste("M:/VR_CSVs/UH-ONR2/",intersect.IDs.UH_ONR2,"/", sep="")

```

### Obtaining each CSV file name for computer 1

This next chunk of code is using the pathways from above to record the names and pathways of each CSV file in Computer 1 and saving them as a data frame. 

```{r obtain pathway csvs and computer data frame for computer 1, warning = FALSE}

# Create a for loop to go into each pathway of a subject's ID folder and extract the names of CSV's present there
# Do this for both pathways
# Computer 1
CSVs.UH_ONR <- list()

for(ii in 1:length(pathway.UH_ONR)) {
  #ii = 1
  # Changes the working directory to each pathway
  setwd(pathway.UH_ONR[[ii]])
  
  # Obtain the CSVs for the folder
  CSVs.current <- list.files()
  
  # Create a vector for the current ID and computer number (Repeat it by the number of CSVs present)
  current.ID <- rep(intersect.IDs.UH_ONR[ii], length(CSVs.current))
  current.pathway <- rep(pathway.UH_ONR[ii], length(CSVs.current))
  current.computer <- rep("Computer 1", length(CSVs.current))
  
  # Create a data frame including the ID, the pathway, CSV, and the computer number
  UH_ONR.df <- data.frame(ID = current.ID,
                          Pathway = current.pathway,
                          CSVs = CSVs.current,
                          Computer = current.computer) 
  
  # Extracts all the names of the CSVs located in that pathway + it's pathway
  CSVs.UH_ONR[[ii]] <- UH_ONR.df
}

CSVs.UH_ONR <- CSVs.UH_ONR %>%
  do.call(rbind,.) %>%
  data.frame()

```

### Obtaining each CSV file name for computer 2

This next chunk of code does the same as above except for the files in computer 2.  

```{r obtain pathway csvs and computer data frame for computer 2, warning = FALSE}

# Create a for loop to go into each pathway of a subject's ID folder and extract the names of CSV's present there
# Do this for both pathways
# Computer 2
CSVs.UH_ONR2 <- list()

for(ii in 1:length(pathway.UH_ONR2)) {
  #ii = 1
  # Changes the working directory to each pathway
  setwd(pathway.UH_ONR2[[ii]])
  
  # Obtain the CSVs for the folder
  CSVs.current <- list.files()
  
  # Create a vector for the current ID and computer number (Repeat it by the number of CSVs present)
  current.ID <- rep(intersect.IDs.UH_ONR2[ii], length(CSVs.current))
  current.pathway <- rep(pathway.UH_ONR2[ii], length(CSVs.current))
  current.computer <- rep("Computer 2", length(CSVs.current))
  
  # Create a data frame including the ID, the pathway, CSV, and the computer number
  UH_ONR.df <- data.frame(ID = current.ID,
                          Pathway = current.pathway,
                          CSVs = CSVs.current,
                          Computer = current.computer) 
  
  # Extracts all the names of the CSVs located in that pathway + it's pathway
  CSVs.UH_ONR2[[ii]] <- UH_ONR.df
}

CSVs.UH_ONR2 <- CSVs.UH_ONR2 %>%
  do.call(rbind,.) %>%
  data.frame()

```


### Removing redundant CSVs from computer 2

Unfortunately, we have some redundant files from early data recording in the project. Some files saved in Computer 2 are identical to files saved in Computer 1. We want to identify these files and associate them with only one pathway before we start to read them in. This will make the computing process more efficient.

```{r identifying duplicates and removing them}
# Identify CSVs in Computer 2 that are not in Computer 1 (save non duplicate CSVs)
nonDuplicate.CSVs <- setdiff(CSVs.UH_ONR2$CSVs, CSVs.UH_ONR$CSVs)

# Overwrite the Computer 2 data frame with one containing only CSVs that are not in Computer 1
CSVs.UH_ONR2 <- CSVs.UH_ONR2 %>%
  filter(CSVs %in% nonDuplicate.CSVs)

```

### Identifying complete subjects from VR data

The logic is as follows. There are four testing days and each day two CSV files are saved- one for GnG and the other for the Nback. On Day 0 (practice day) a 30 minute practice session CSV is saved for both tasks. On day 1 the baseline CSVs are saved. On day 2 the intense exercise CSVs are saved. And lastly, on day 3 the sleep deprivation CSVs are saved. Thus, a subject that completed all testing days will have 8 CSVs. 

We will be merging the data frames from both computers created in the previous scripts and extracting the ID numbers that have 8 CSVs saved. We will then use this information to create a new variable indicating whether the subject is complete or not. 

```{r identifying complete subjects}
# Merge the datasets from above
CSVs.merged.UH_ONR <- CSVs.UH_ONR %>%
  rbind(CSVs.UH_ONR2)

# Total unique ID's from all subjects that have a VR session saved
paste("There is at least one CSV file saved from", length(unique(CSVs.merged.UH_ONR$ID)), "participants", sep= " ")

# IDs that have 8 file names
completed.IDs <- CSVs.merged.UH_ONR %>%
  group_by(ID) %>%
  count() %>%
  filter(n == 8) %>%
  select(ID) %>%
  unlist() %>% unname()

# Complete ID's and their pathways 
CSVs.merged.UH_ONR <- CSVs.merged.UH_ONR %>%
  mutate(Status = ifelse(ID %in% completed.IDs, "Complete", "Incomplete"))

# Total unique ID's from all subjects that have all VR sessions accounted for
paste("All VR sessions accounted for", length(completed.IDs), "participants", sep= " ")

```

### Read in the files

We will now read in the files and save them into a list. This takes about 30 seconds. Additionally, as each file is being read, a new variable called computer will be added that indicates if the data was recorded in Computer 1 or in Computer 2. 

```{r reading in the files}
# Read in the files
all.CSVs <- list()

for(ii in 1:nrow(CSVs.merged.UH_ONR)) {
   
  # Current file name and its pathway 
  current.csv <- paste(CSVs.merged.UH_ONR$Pathway[ii],  CSVs.merged.UH_ONR$CSVs[ii], sep="")
    
  # Read in and save the current CSV in a list
  read.csv <- read.csv(current.csv)
  
  # Mutate the csv to include which computer it came from
  read.csv$Computer <- rep(CSVs.merged.UH_ONR$Computer[ii], times = nrow(read.csv))
  
  # Save the mutated CSV
  all.CSVs[[ii]] <- read.csv
  
  # Name the list by the ID and CSV
  names(all.CSVs)[[ii]] <- paste(CSVs.merged.UH_ONR$ID[ii],CSVs.merged.UH_ONR$CSVs[ii])
}

# Check to see that the above code worked
paste("There are", length(all.CSVs),"CSV files that were read in", sep =" ")

# Half of the CSVs, the ones for GnG have the following dimensions
dim(all.CSVs[[8]])

# The other half of the CSVs, the ones for Nback each have the following dimensions
dim(all.CSVs[[9]])

```
### Map all of the read csv files into a new data frame

We will now create a data frame that contains all of the CSVs read from above in the variable tibble. We will add additional variables to this data frame such as the ID from that dataset, the day of testing, the task type (Go/No-Go or Nback) and the computer used to record the data. 


```{r Using the map function}
# Create a new data frame that will contain all CSV information
all.data <- data.frame(file.num = 1:length(all.CSVs))

# Use the map function to make a variable called tibble, where each row contains the full data from the VR CSV
all.data$tibbles <- map(all.CSVs, as_tibble)

# Create for loops that extract information from the first row of each data frame in the tibbles variable
# This will include ID, day of testing, task type (GnG/Nback)

ID.list <- list()
testing.date <- list()
task.type <- list()
Computer.num <- list()

for(ii in 1:nrow(all.data)) {

# Obtain the first tibble and save it into an object
current.dataset <- all.data$tibbles[[ii]]

# Extract the following information and save it to the all.data data frame
ID.list[[ii]] <- unique(current.dataset$UserID)
testing.date[[ii]] <- unique(substr(current.dataset$StartDate,1,10))
Computer.num[[ii]] <- unique(current.dataset$Computer)


if(gsub("[^a-zA-Z]", "", current.dataset$BlockID[1]) == "G") {
  task.type[ii] <- "Go/NoGo"

} else if(gsub("[^a-zA-Z]", "", current.dataset$BlockID[1]) == "N") {
  task.type[ii] <- "N-back"
  
}

}

# Add the lists back into the dataframe
all.data$ID <- unlist(ID.list)
all.data$Testing.Date <- unlist(testing.date)
all.data$Task.type <- unlist(task.type)
all.data$Computer.num <- unlist(Computer.num)

```


### Introducing the Visitor Log and labeling the dates

Since the CSV file names do not contain information about the testing day and since that information is also not available inside the CSV files, we have to manually turn to the Visitor Log. This is an excel sheet where ONR data collectors manually input the dates of when participants completed their visiting session and also add any additional notes about how testing went. We will be using this excel sheet to help us name our CSV files by testing day. 

Additionally for this to work, we had to convert any NA's from the dates of the visitor log into zeroes (for more info look at the index part of the code) and dropped any NA's in the ID column. 

The final produce is the all data.frame with the proper day types for each CSV file. This was manually inspected and shown to be correct by comparing the final data set with the dates from the Visitor Log. 

Lastly, and data set is shown at the bottom that indicate all CSV files that should have been logged in the Visitor Log but were not. 

```{r introducing the visitor log, warning = FALSE}
# Set working directory to the visitor log
setwd("C:/Users/lledesma.TIMES/Documents/ONR/Visitor_log")

# Load in the Visitor Log
VisitorLog.org <- read_excel("Visiting_Log_must_manually_update.xlsx")

# Keep only the variables of interest
VisitorLog <- VisitorLog.org %>%
  select(ID, `Day 0 Date`, `Day 1 Date`, `Day 2 Date`, `Day 3 Date`)

# Convert visitor log into long
VisitorLog.Long <- VisitorLog %>%
  pivot_longer(-ID) %>%
  rename(Day.type = name,
         Date = value) %>%
  mutate(ID = as.numeric(ID),
         Day.type = substr(Day.type, 1, 5),
         Date = substr(Date,1,10))

# Convert all missing dates in the Visitor Log into "0"
VisitorLog.Long <- VisitorLog.Long %>%
  mutate(Date = ifelse(is.na(Date),"0",Date))

# If any other variable have missing data then drop the rows to that variable
VisitorLog.Long <- drop_na(VisitorLog.Long)

# Check to see if there is any missing data
missing.data <- VisitorLog.Long %>%
  filter(!complete.cases(.))

paste("This is a check for missing data that should be 0. Right now it is:", nrow(missing.data))

# Create a for loop that adds the day type to the all.data data frame using the information from the Visitor Log
Day.type <- list()

for(ii in 1:nrow(all.data)) {
  
  # Extract the ID from the current row in all data
  current.ID <- all.data$ID[ii]
  current.Testing.Date <- all.data$Testing.Date[ii]
  
  # Use this ID to filter the rows of the Visitor Log that match with it
  filtered.VisitorLog <- VisitorLog.Long %>%
    filter(ID %in% current.ID)
  
  # If the Date from one of these rows matches the of the current all data row then copy over the Day type to all.data
  # If it does not then write that it is missing from the Visitor Log
  if(current.Testing.Date %in% filtered.VisitorLog$Date) {
    
    # Obtain the index (Boolean) to where this condition is true
    index <- filtered.VisitorLog$Date == current.Testing.Date
    
    # Save the correct day type
    Day.type[[ii]] <- filtered.VisitorLog$Day.type[index]
    
  } else {
    
    # Save that the date is missing from the Visitor Log 
    Day.type[[ii]] <- "Date not saved in the Visitor Log"
    
  }
  
}

# Add the Day.type list information into all.data
all.data$Day.type <- unlist(Day.type)

# Chance the order of columns for easier manually viewing and sort them by ID and Day.type
all.data <- all.data %>% select(file.num, ID, Day.type, Testing.Date, everything()) %>%
  arrange(ID,Day.type) 


# Let's see if there are errors with the Visitor Log
all.data %>%
  filter(Day.type == "Date not saved in the Visitor Log") %>%
  select(-tibbles)


```

### Adding the day type into the original datasets

We know the Day Type now in the all.data set, however, we also want to introduce this information into the original tibbles. This way when we saved this transformed data for later processing and then analysis, the day types would be included.

```{r adding the day types into the tibbles}
# Create a loop to add the Day type as a column into each tibble
for(ii in 1:nrow(all.data)) {

  # Obtain the tibble of the current row
  current.dataset <- all.data$tibbles[[ii]]
  
  # Add the Day type to this tibble, aka the original CSV file
  current.dataset$Day.Type <- rep(all.data$Day.type[ii], nrow(current.dataset))
  
  # Override the tibble in the all data data frame with the tibble that has a day type added
  all.data$tibbles[[ii]] <- current.dataset
}


```


### Splitting the data based on their tasks

Now that we have our data in an organized manner with the ID, Day Type (Day0-3), Testing Date, Task Type (Go/No-Go or N-back), and Computer number (1 or 2), we can start the process of combining the data into one large dataset by task type.  

```{r splitting the dataset by task type}
# Save all the GnG data into a new object
all.GnG <- all.data %>%
  filter(Task.type == "Go/NoGo")

# Save all of the Nback data into a new object
all.Nback <- all.data %>%
  filter(Task.type == "N-back")

# Collapse both new objects into a single dataframe with all the tibbles (CSVs) stacked on top of each other
all.GnG.tibbles <- do.call(rbind, as.list(all.GnG$tibbles))
all.Nback.tibbles <- do.call(rbind, as.list(all.Nback$tibbles))

```

### Saving files

Now we will save GnG and Nback data with Day Type and Computer Number added as variables into two CSV files. 

```{r saving the data}
# Set saving directory
setwd("C:/Users/lledesma.TIMES/Documents/ONR/GnG_and_Nback_behavioral_data_preprocessing/Processed Data")

# Save the data as CSVs
write.csv(all.GnG.tibbles, "GnG.day.type.added.csv")
write.csv(all.Nback.tibbles, "Nback.day.type.added.csv")

```
