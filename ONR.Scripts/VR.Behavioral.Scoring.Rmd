---
title: "VR Behavioral Scoring"
author: "Leandro Ledesma"
date: "2024-02-10"
output: html_document
---

### Universal block code settings

```{r setup}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(comment = NULL)

```

### Load in the data manipulation packages first

```{r loading in the packages, warning = FALSE}
library(tidyverse)
library(ggplot2)
library(ggpubr)
library(readxl)
library(kableExtra)

```

### Load in the data

The Day.Labeling script (Step 1) cleaned the VR behavioral data and now it is ready for processing to be used for later analysis. 

```{r load in the data, warning = FALSE}
# Set working directory
setwd("C:/Users/lledesma.TIMES/Documents/ONR/GnG_and_Nback_behavioral_data_preprocessing/Processed Data")

# Load in the data
GnG.original <- read.csv("GnG.day.type.added.csv")
Nback.original <- read.csv("Nback.day.type.added.csv")

# What is the dimensions
dim(GnG.original)
dim(Nback.original)

```

The data dimensions above are gigantic and unnecessary. This is because each person had roughly 1,500 trials for each GnG session and around 600 trials for the Nback. Our goal is to reduce these dimensions for each person.

### Data reduction Go/No-Go

We will be reducing the data by obtaining the scores of each person on variables of interest. This can be changed later to include more rows. For the Go/No-Go there are Day 0's (practice days) and practice sessions that need to be removed. Then we can label the trials by Go or No-Go and finally use the group_by function to reduce the data to give us the mean scores for trial type for each ID on their respective testing day. 

```{r GnG data reduction}
# Remove Day 0 from our dataset or problematic day types (not noted in the visitor log)
GnG.removed.days <-  GnG.original %>%
  filter(!(Day.Type %in% c("Day 0", "Date not saved in the Visitor Log")))

# The dimensions of the new dataset
dim(GnG.removed.days)

# Remove practice trials
GnG.practice.blocks <- c(paste("G",1:5,"0",sep=""))
GnG.removed.practice.blocks <- GnG.removed.days %>%
  filter(!(BlockID %in% GnG.practice.blocks))

# The dimensions of the new dataset
dim(GnG.removed.practice.blocks)

# Extra check
GnG.removed.practice.blocks %>%
  select(BlockName) %>%
  table() %>%
  prop.table() %>%
  names()

# Remove the Day 0's still present in the data
remaining.practice.trials <-c("Colors  Shape  and Arrow  Day 0",
                              "Color  Shape and Reverse Arrow  Day 0",
                              "Colors and Shape  Day 0",
                              "Colors and Shape with fixed ISI  Day 0",
                              "Saber Color Matching  Day 0")
  
GnG.removed.practice.blocks <- GnG.removed.practice.blocks %>%
  filter(!(BlockName %in% remaining.practice.trials))

# Extra check again 
GnG.removed.practice.blocks %>%
  select(BlockName) %>%
  table() %>%
  prop.table() %>%
  names()

# Add Go and No-Go Labels (This was tested and it came out correct 20/80)
go.trials <- c("G1", "G5", "G8", "G12")
GnG.trial.type <- GnG.removed.practice.blocks %>%
  mutate(Trial.Type = ifelse(ItemID %in% go.trials, "Go", "No-Go"))

# Reduce the dimensions even more by grouping and obtaining performance score for each block type
GnG.grouped.Trial.Type <- GnG.trial.type %>%
  group_by(UserID, BlockName, Trial.Type, Day.Type) %>%
  summarize(trial.mean.correct = round(mean(Correct),2))

# Create another data frame that reduced dimensions but only for correct reaction times of Go-Trials
GnG.grouped.Reaction.Time <- GnG.trial.type %>%
  filter(Trial.Type == "Go" & Correct ==  1) %>%
  group_by(UserID, BlockName, Day.Type) %>%
  summarize(mean.RT = mean(TimeToImpact))

```

### Data reduction Nback

Same procedure as above. We will be removing practice days and practice sessions then labeling the trials by either target or distractor Afterwards we will obtain the mean scores of performance for each trial type for all participants on their respective testing days.

This dataset does not have an item ID to determine between target stimuli and non-target stimuli (distractor). Thus we devised a way to measure this using code. Our N-back is a 2-back, meaning that the participant must hit a shape that matches two shapes ago. The CSV files recorded indicate the order of shapes presented in row order. Thus the first item presented was recorded in row one and the second item was recorded in row two and so on until the completion of the task. Knowing this, we can copy and paste the the order of items and shift it two rows down. Then, any rows that match between these two variables (original and the shifted two down) will indicate a target trial- below will be a demonstration.

Doing this method seems to be correct. However, it is important to note that we were expecting to have 80% non-target and 20% target trials per N-back task, but instead we are getting roughly 20-23% target trials. This is important to be aware of but shouldn't raise suspicion to the scoring code or the way the game was designed. 

```{r Nback data reduction}
# Remove Day 0 from our dataset or problematic day types (not noted in the visitor log)
Nback.removed.days <- Nback.original %>%
    filter(!(Day.Type %in% c("Day 0", "Date not saved in the Visitor Log")))

# The dimensions of our new dataset
dim(Nback.removed.days)

# Keep all non practice blocks (there are not practice trials but blocks)
non.practice.blocks <- c("N1","N2","N3","N4")
Nback.kept.non.practice.blocks <- Nback.removed.days %>%
  filter(BlockID %in% non.practice.blocks)

# The dimensions of our new dataset
dim(Nback.kept.non.practice.blocks)

# Extra check
Nback.kept.non.practice.blocks %>%
  select(BlockName) %>%
  table() %>%
  prop.table() %>%
  names()



#####################################################################################################
### Example of the proposed code to identify target trials
example.session <- Nback.kept.non.practice.blocks %>%
  filter(UserID == 3 & Day.Type == "Day 1")

## Test: Add the additional variable to it identify target trials and shift it down two rows
example.session$ItemID2 <- c("-", "-", example.session$ItemID[1:(length(example.session$ItemID)-2)])

example.session <- example.session %>%
  mutate(Trial.Type = ifelse(ItemID == ItemID2, "Target", "Distractor")) %>%
  select(ItemID, ItemID2, Trial.Type, Correct, Reacted)

# View the example of how scoring works
example.session %>%
  head(40) %>%
  kbl() %>%
  kable_paper(full_width = F)


# Obtain the proportion of target trials
example.session %>%
  select(Trial.Type) %>%
  table() %>%
  prop.table() %>%
  round(2)
##################################################################################################
# Add target and distracter labels to all Nback sessions
# Create an empty list
all.Nback.sessions <- list()

# Create a 'file.name' for file extraction
Nback.file.names <- Nback.kept.non.practice.blocks %>% select(UserID, Day.Type) %>% group_by(UserID, Day.Type) %>% unique()


# Run the loop 
for(ii in 1:nrow(Nback.file.names)) {
  
  # Extract the ID in the list
  current.ID <- Nback.file.names$UserID[ii]
  
  # Extract the  Day Type in the list
  current.Day.Type <- Nback.file.names$Day.Type[ii]
  
  # Use ID and Day Type to subet one CSV file from the Nback
  current.Nback <- Nback.kept.non.practice.blocks %>%
    filter(UserID == current.ID & Day.Type == current.Day.Type)
  
  # Add the second variable that duplicates ItemID and shifts it down two rows
  current.Nback$ItemID2 <- c("-", "-", current.Nback$ItemID[1:(length(current.Nback$ItemID)-2)])

  # Use the second variable to identify target trials by marking matching rows as 'Target
  current.Nback <- current.Nback %>%
  mutate(Trial.Type = ifelse(ItemID == ItemID2, "Target", "Distractor")) %>%
    select(X, UserID, BlockID, ItemID, ItemID2, Trial.Type, everything())
  
  # Save this manipulation into the list
  all.Nback.sessions[[ii]] <- current.Nback
}

# Save the list with the transformation back as a dataframe
Nback.trial.type <- all.Nback.sessions%>%
  do.call(rbind,.) %>%
  data.frame()

# Reduce the dimensions even more by grouping and obtaining performance score for each block type
Nback.grouped.Trial.Type <- Nback.trial.type %>%
  group_by(UserID, BlockName, Trial.Type, Day.Type) %>%
  summarize(trial.mean.correct = round(mean(Correct),2))

# Create another data frame that reduced dimensions but only for correct reaction times of Nback
Nback.grouped.Reaction.Time <- Nback.trial.type %>%
  filter(Trial.Type == "Target" & Correct ==  1) %>%
  group_by(UserID, BlockName, Day.Type) %>%
  summarize(mean.RT = mean(TimeToImpact))

### Additionally- we are going to save this data frame to the Nback as a reaction to a target trial being correct
# This means that it ignores trials being wrong by not hitting with the arrows.
Nback.grouped.Reaction.Target <- Nback.trial.type %>%
  filter(Trial.Type == "Target") %>%
  group_by(UserID, BlockName, Trial.Type, Day.Type) %>%
  summarize(target.mean.reacted = round(mean(Reacted),2))

```

### Save the data

```{r save the data, warning = FALSE}
# Set the save directory
setwd("C:/Users/lledesma.TIMES/Documents/ONR/GnG_and_Nback_behavioral_data_preprocessing/Processed Data")

# Save the data
write.csv(x = GnG.grouped.Trial.Type,
          file = "GnG.trial.type.csv")

write.csv(x = GnG.grouped.Reaction.Time,
          file = "GnG.reaction.time.csv")

write.csv(x = Nback.grouped.Trial.Type,
          file = "Nback.trial.type.csv")

write.csv(x = Nback.grouped.Reaction.Time,
          file = "Nback.reaction.time.csv")

write.csv(x = Nback.grouped.Reaction.Target,
          file = "Nback.target.reacted.csv")

```

