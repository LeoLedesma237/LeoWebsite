---
title: "VR Behavioral Scoring"
author: "Leandro Ledesma"
date: "2024-02-10"
output: html_document
---

### Universal block code settings

```{r setup}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(comment = NULL)

```

### Load in the data manipulation packages first

```{r loading in the packages, warning = FALSE}
library(tidyverse)
library(ggplot2)
library(ggpubr)
library(readxl)
library(kableExtra)

```

### Load in the data

The Day.Labeling script (Step 1) cleaned the VR behavioral data and now it is ready for processing to be used for later analysis. 

```{r load in the data, warning = FALSE}
# Set working directory
setwd("C:/Users/lledesma.TIMES/Documents/ONR/GnG_and_Nback_behavioral_data_preprocessing/Processed Data")

# Load in the data
GnG.original <- read.csv("GnG.day.type.added.csv")
Nback.original <- read.csv("Nback.day.type.added.csv")

# What is the dimensions
dim(GnG.original)
dim(Nback.original)

# Data cleaning- removing variable x
GnG.original <- GnG.original %>% select(-X)
Nback.original <- Nback.original %>% select(-X)
```

The data dimensions above are gigantic and unnecessary. This is because each person had roughly 1,500 trials for each GnG session and around 600 trials for the Nback. Our goal is to reduce these dimensions for each person.

### Data reduction Go/No-Go Part 1 - Cleaning

We will be reducing the data by obtaining the scores of each person on variables of interest. This can be changed later to include more rows. For the Go/No-Go there are Day 0's (practice days) and practice sessions that need to be removed. Then we can label the trials by Go or No-Go and finally use the group_by function to reduce the data to give us the mean scores for trial type for each ID on their respective testing day. 

```{r GnG data reduction cleaning portion}
# Remove Day 0 from our dataset or problematic day types (not noted in the visitor log)
GnG.removed.days <-  GnG.original %>%
  filter(!(Day.Type %in% c("Day 0", "Date not saved in the Visitor Log")))

# The dimensions of the new dataset
dim(GnG.removed.days)

# Remove practice trials
GnG.practice.blocks <- c(paste("G",1:5,"0",sep=""))
GnG.removed.practice.blocks <- GnG.removed.days %>%
  filter(!(BlockID %in% GnG.practice.blocks))

# The dimensions of the new dataset
dim(GnG.removed.practice.blocks)

# Extra check
GnG.removed.practice.blocks %>%
  select(BlockName) %>%
  table() %>%
  prop.table() %>%
  names()

# Remove the Day 0's still present in the data
remaining.practice.trials <-c("Colors  Shape  and Arrow  Day 0",
                              "Color  Shape and Reverse Arrow  Day 0",
                              "Colors and Shape  Day 0",
                              "Colors and Shape with fixed ISI  Day 0",
                              "Saber Color Matching  Day 0")
  
GnG.removed.practice.blocks <- GnG.removed.practice.blocks %>%
  filter(!(BlockName %in% remaining.practice.trials))

# Extra check again 
GnG.removed.practice.blocks %>%
  select(BlockName) %>%
  table() %>%
  prop.table() %>%
  names()

# Add Go and No-Go Labels (This was tested and it came out correct 20/80)
go.trials <- c("G1", "G5", "G8", "G12")
GnG.trial.type <- GnG.removed.practice.blocks %>%
  mutate(Trial.Type = ifelse(ItemID %in% go.trials, "Go", "No-Go"))


```



### Data reduction Go/No-Go Part 2 - Actual data reduction


```{r GnG data reduction part}

# Reduce the dimensions even more by grouping and obtaining performance score for each block type
# Every subject should have 30 rows: 2 (trial types) x 5 (BlockName) x 3 (Days) = 30
GnG.grouped.Trial.Type <- GnG.trial.type %>%
  group_by(UserID, BlockName, Trial.Type, Day.Type) %>%
  mutate(trial.mean.correct = round(mean(Correct),2),
         mean.score = round(mean(ItemScore)),
         trial.num = length(Correct)) %>%
  ungroup() %>%
  select(UserID, BlockName, Trial.Type, Day.Type, mean.score, trial.mean.correct, trial.num) %>%
  unique()


# Create another data frame that reduced dimensions but only for correct reaction times of Go-Trials
GnG.grouped.Reaction.Time <- GnG.trial.type %>%
  group_by(UserID,Trial.Type, Correct, BlockName, Day.Type) %>%
  summarize(mean.RT = mean(TimeToImpact))

```


### Data reduction Go/No-Go Part 3 - Quality Control

```{r check the quality of the data, results = 'asis', echo = FALSE}
paste("This section is the quality control for: 'GnG.grouped.Trial.Type'")
paste("This dataset contains",length(unique(GnG.grouped.Trial.Type$UserID)),"unique IDs.")
paste("The following table shows the frequency of each GnG Condition for all subjects for each trial type:")
table(GnG.grouped.Trial.Type$BlockName, GnG.grouped.Trial.Type$Day.Type, GnG.grouped.Trial.Type$Trial.Type)
paste("Let's view the distribution of scores for Go and No-Go trials, averaged to no include days")

GnG.grouped.Trial.Type %>%
  ggplot(aes(x = trial.mean.correct)) +
  geom_histogram() +
  facet_wrap(~Trial.Type)

paste("This section is the quality control for: 'GnG.grouped.Reaction.Time'")
paste("This dataset contains",length(unique(GnG.grouped.Reaction.Time$UserID)),"unique IDs.")
paste("Quality check 1: Are there -1 for reaction times for correct go trials?")
summary(GnG.grouped.Reaction.Time$mean.RT[GnG.grouped.Reaction.Time$Trial.Type == "Go" & GnG.grouped.Reaction.Time$Correct == 1])

paste("What is the proportion of Go/No-Go trials in the original dataset?")
data.frame(Proportion = cbind(prop.table(table(GnG.trial.type$Trial.Type))))

```



### Data reduction Nback

Same procedure as above. We will be removing practice days and practice sessions then labeling the trials by either target or distractor Afterwards we will obtain the mean scores of performance for each trial type for all participants on their respective testing days.

This dataset does not have an item ID to determine between target stimuli and non-target stimuli (distractor). Thus we devised a way to measure this using code. Our N-back is a 2-back, meaning that the participant must hit a shape that matches two shapes ago. The CSV files recorded indicate the order of shapes presented in row order. Thus the first item presented was recorded in row one and the second item was recorded in row two and so on until the completion of the task. Knowing this, we can copy and paste the the order of items and shift it two rows down. Then, any rows that match between these two variables (original and the shifted two down) will indicate a target trial- below will be a demonstration.

Doing this method seems to be correct. However, it is important to note that we were expecting to have 80% non-target and 20% target trials per N-back task, but instead we are getting roughly 20-23% target trials. This is important to be aware of but shouldn't raise suspicion to the scoring code or the way the game was designed. 

```{r Nback data reduction}
# Remove Day 0 from our dataset or problematic day types (not noted in the visitor log)
Nback.removed.days <- Nback.original %>%
    filter(!(Day.Type %in% c("Day 0", "Date not saved in the Visitor Log")))

# The dimensions of our new dataset
dim(Nback.removed.days)

# Keep all non practice blocks (there are not practice trials but blocks)
non.practice.blocks <- c("N1","N2","N3","N4")
Nback.kept.non.practice.blocks <- Nback.removed.days %>%
  filter(BlockID %in% non.practice.blocks)

# The dimensions of our new dataset
dim(Nback.kept.non.practice.blocks)

# Extra check
Nback.kept.non.practice.blocks %>%
  select(BlockName) %>%
  table() %>%
  prop.table() %>%
  names()


##################################################################################################
# Add target and distracter labels to all Nback sessions
# Create an empty list
all.Nback.sessions <- list()

# Create a 'file.name' for file extraction
Nback.file.names <- Nback.kept.non.practice.blocks %>% select(UserID, Day.Type) %>% group_by(UserID, Day.Type) %>% unique()


# Run the loop 
for(ii in 1:nrow(Nback.file.names)) {

  # Extract the ID in the list
  current.ID <- Nback.file.names$UserID[ii]
  
  # Extract the  Day Type in the list
  current.Day.Type <- Nback.file.names$Day.Type[ii]
  
  # Use ID and Day Type to subset one CSV file from the Nback
  current.Nback <- Nback.kept.non.practice.blocks %>%
    filter(UserID == current.ID & Day.Type == current.Day.Type)
  
  # Split the Figure variable to obtain the sequence of shown stimuli and save that as a separate data frame
  split.Figure.df <- str_split(current.Nback$Figure, pattern = "_") %>%
    do.call(rbind,.) %>%
    data.frame() %>%
    select(-X3)
  
  # Give them names associated with what is being measure
  names(split.Figure.df) <- c("Shape", "Sequence")

  # Introduce them into the main Nback dataframe
  current.Nback2 <- cbind(current.Nback, split.Figure.df)
  
  # Add the second variable that duplicates ItemID and shifts it down two rows
  current.Nback2$ItemID2 <- c("-", "-", current.Nback2$ItemID[1:(length(current.Nback2$ItemID)-2)])

  # Use the second variable to identify target trials by marking matching rows as 'Target
  current.Nback2 <- current.Nback2 %>%
    mutate(Trial.Type = case_when(
      
      ItemID == ItemID2 & Sequence %in% c(2:19) ~ "Target",
      ItemID != ItemID2 & Sequence %in% c(2:19) ~ "Non-Target",
      TRUE ~ "First/Second Trial"
      
    )) %>%
    select(UserID, BlockID, ItemID, ItemID2, Trial.Type, everything())
  
  # Save this manipulation into the list
  all.Nback.sessions[[ii]] <- current.Nback2
}

# Save the list with the transformation back as a dataframe
Nback.trial.type <- all.Nback.sessions%>%
  do.call(rbind,.) %>%
  data.frame()



# Reduce the dimensions even more by grouping and obtaining performance score for each block type
Nback.grouped.Trial.Type <- Nback.trial.type %>%
  group_by(UserID, BlockName, Trial.Type, Day.Type) %>%
  summarize(trial.mean.correct = round(mean(Correct),2),
            mean.score = round(mean(ItemScore)),
            trial.num = length(Correct))

# Create another data frame that reduced dimensions but only for correct reaction times of Nback
Nback.grouped.Reaction.Time <- Nback.trial.type %>%
  group_by(UserID,Trial.Type, Correct, BlockName, Day.Type) %>%
  summarize(mean.RT = mean(TimeToImpact))

### Additionally- we are going to save this data frame to the Nback as a reaction to a target trial being correct
# This means that it ignores trials being wrong by not hitting with the arrows.
Nback.grouped.Reaction.Target <- Nback.trial.type %>%
  group_by(UserID, BlockName, Trial.Type, Day.Type) %>%
  mutate(target.mean.reacted = round(mean(Reacted),2),
         trial.num = length(Reacted)) %>%
  ungroup() %>%
  select(UserID, BlockName, Trial.Type, Day.Type, target.mean.reacted, trial.num) %>%
  unique()


```


### Nback quality control (to send to Mark)

Identifying that there are 20% Target trials as expected. Also identifying that there are no trials where a target that is correct has a -1 reaction time. 

```{r nback quality control}
### Quality control, get the frequency of each 
data.frame(Frequency = cbind(table(Nback.trial.type$Trial.Type))) %>%
  mutate(Total = sum(Frequency),
         Percentage = Frequency/Total * 100)


# Checking a -1 value for reaction time for correct target trials
Nback.trial.type %>%
  filter(Trial.Type == "Target" & Correct == 1) %>%
  select(TimeToImpact) %>%
  unlist() %>%
  summary()

```



### Reduce data dimensionality for vigilance decrement 


```{r reduce data dimensionality for vigilance decrement}
# Reduce the data dimensionality for the GnG
# We can identify the order by taking advantage of the unique function
# unique tells us two things, the first is all of the unique values in a variable
# and secondly the order of those unique values in the dataset- we can use this to our advantage

unique.IDs <- unique(GnG.trial.type$UserID)
unique.Days <- unique(GnG.trial.type$Day.Type)

all.ordered.list <- list()

for (ii in 1:length(unique.IDs)) {

  # Extract the first ID
  current.ID <- unique.IDs[ii]
  current.data <- GnG.trial.type %>%
    filter(UserID == current.ID)

  all.days.list <- list()
  for (iii in 1:3) {
    
    # Extract by day
    current.day <- unique.Days[iii]
    current.data.day <- current.data %>%
      filter(Day.Type == current.day)
    
    # Extract the current order of blocks for this day
    block.order <- unique(current.data.day$BlockName)
    
    # Introduce a new variable that adds the order of each block displayed
    current.data.day <- current.data.day %>%
      mutate(Order = case_when(
        BlockName == block.order[1] ~ 1,
        BlockName == block.order[2] ~ 2,
        BlockName == block.order[3] ~ 3,
        BlockName == block.order[4] ~ 4,
        BlockName == block.order[5] ~ 5,
        TRUE ~ 0
      ))
    
    all.days.list[[iii]] <- current.data.day
  }
    
  all.ordered.list[[ii]] <- do.call(rbind,all.days.list)
}

# Save it as one large dataset
GnG.ordered <- do.call(rbind, all.ordered.list)


# Data dimensionality
GnG.ordered.reduced <- GnG.ordered %>%
  mutate(BlockName_and_order = paste(BlockName, Order)) %>%
  group_by(UserID, BlockName_and_order, Trial.Type, Day.Type) %>%
  summarize(trial.mean.order.correct = round(mean(Correct),2),
            mean.score = round(mean(ItemScore)),
            trial.num = length(Correct)) %>%
  arrange(Day.Type)

# Extract order and blockname from the variable that contains both
GnG.ordered.reduced$Order <-  as.numeric(gsub("\\D", "", GnG.ordered.reduced$BlockName_and_order))
GnG.ordered.reduced$BlockName <- gsub("[^a-zA-Z]", " ", GnG.ordered.reduced$BlockName_and_order)

# Remove the variable with information on both
GnG.ordered.reduced <- GnG.ordered.reduced %>%
  ungroup() %>%
  select(-BlockName_and_order)


head(table(GnG.ordered$UserID, GnG.ordered$Order))
```



### Save the data (locally)

```{r save the data, warning = FALSE}
# Set the save directory
setwd("C:/Users/lledesma.TIMES/Documents/ONR/GnG_and_Nback_behavioral_data_preprocessing/Processed Data")

# Save the data
write_csv(x = GnG.grouped.Trial.Type,
          file = "GnG.trial.type.csv")

write_csv(x = GnG.grouped.Reaction.Time,
          file = "GnG.reaction.time.csv")

write_csv(x = Nback.grouped.Trial.Type,
          file = "Nback.trial.type.csv")

write_csv(x = Nback.grouped.Reaction.Time,
          file = "Nback.reaction.time.csv")

write_csv(x = Nback.grouped.Reaction.Target,
          file = "Nback.target.reacted.csv")

write_csv(x = GnG.ordered.reduced,
          file = "GnG.conditions.ordered.csv")

```

### Save the data to the server

```{r save the data to the server, warning = FALSE}
# Set another save directory
setwd("M:/Qualtrics_Data/Processed data/VR Performance")

# Save the data
write_csv(x = GnG.grouped.Trial.Type,
          file = "GnG.trial.type.csv")

write_csv(x = GnG.grouped.Reaction.Time,
          file = "GnG.reaction.time.csv")

write_csv(x = Nback.grouped.Trial.Type,
          file = "Nback.trial.type.csv")

write_csv(x = Nback.grouped.Reaction.Time,
          file = "Nback.reaction.time.csv")

write_csv(x = Nback.grouped.Reaction.Target,
          file = "Nback.target.reacted.csv")

write_csv(x = GnG.ordered.reduced,
          file = "GnG.conditions.ordered.csv")

```


```

