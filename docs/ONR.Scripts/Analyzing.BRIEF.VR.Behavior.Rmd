---
title: "Data Analyzing BRIEF and VR Behavioral Data"
author: "Leandro Ledesma"
date: "2024-02-10"
output: html_document
---

### Our Measures of Interest

We are interested in determining whether scores obtained for executive functioning domains in the BRIEF Self-Report are relate to two cognitive tasks performed in virtual reality (VR). For our study, we have two nearly one hour long VR Sessions where subjects engage in a Go/No-Go (GnG) and N-back paradigm. The GnG is a commonly used measure of inhibition in EEG research that habituates a behavior by displaying high frequency of Go signals (80%), which then have to be stopped during the presence of a No-Go signal (20%). There are 1,050 trials in each GnG testing session and  5 different versions of the GnG (block sessions) within each session. The N-back, specifically the 2-back, is a paradigm that measures working memory. Several stimuli are presented one by one and when an item matches an item seen two items back, that item (target) needs to be hit. Overall there are roughly 600 trials and about 20% of them are target trials. Additionally, there are 4 different versions of the N-back (block sessions) within each session. 

Performance in the VR Tasks was calculated by taking the sum of correct trials for each participant and dividing it by the total number of trials presented. This was done for all Go and No-Go trials respectively, and for each version of the GnG. Similarly, this was done for target trials in the Nback. For the GnG, we are interested in the version of the task that best measures inhibition- thus we are only using the 'Colors and Shape' block session for our analysis. This particular block displays green cubes as Go trials and green pyramids or red cubes as No-Go trials. For the Nback, we have four block sessions that all include arrow conditions and half contain distractors, such as large green 3D shapes taking up space in the background or smaller shapes that sometimes dart across the screen. Again, we are interested in the block session that best captures working memory, so we will using the block session with forward arrows and no distractors. 

The BRIEF Self-Report contains questions for several different domains encompassing executive functioning. We were interested in questions that assessed inhibition and working memory. Thus, T-scores were obtained for each subject on both inhibition and working memory scales. The BRIEF however is measuring problems with these scales, meaning that higher T-scores means more problems with that scale. 

### Variables that measure performance

In the GnG, the variable 'correct' was used to calculate the mean performance for each person at each block session. This variable is binary (0 or 1) and it informs whether the trial was done correctly or not. This means that for a Go-trial to be correct, the green cube showed must have been hit in a specific amount of time and for No-Go trials, the green pyramid or red cube must not have been struck. For the Nback, we used the variable 'reacted' instead to calculate mean performance. Since the Nback has four versions that all include arrows, and we are more interested in the ability to identify target trials rather than identifying target trials and hitting in the direction of the arrow, we are using the scores from React to calculate performance. This will allow us to obtain the mean of identifying targets for each subject, which is one way to measure working memory from the way this paradigm was constructed.

### Cross-sectional analysis

The data we are loading into our workspace contains information from multiple testing sessions. Overall, the initial study is collecting data from four testing days (One practice, one baseline, and two stressor conditions). We are only interested in the VR behavioral data from baseline thus, only Day 1 will be included into our analysis. For the BRIEF Self-Report, this information was collected during the very first day of testing (practice session). Thus, we will be comparing scores between these two days but it will not be repeated measures and instead treated as cross-sectional. 


### Hypotheses

There are very to the point hypotheses. That the lower the subject's T-score is in the BRIEF scale, the better the performance will be in the VR task. 

### Universal block code settings

```{r setup}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(comment = NULL)

```

### Load in the data manipulation packages first

```{r loading in the packages, warning = FALSE}
library(tidyverse)
library(ggplot2)
library(ggpubr)
library(readxl)
library(lmtest) # bptest() function for homoscedasticity
library(kableExtra)
library(boot)

```

### Load in the data

As mentioned above, we are only interested in performance on Day 1 for the 'Colors and Shape' block session for the GnG and the forward arrows no distractor condition in the Nback. Thus, these data will remain for the rest of the analysis. 

```{r load in the data, warning = FALSE}
# Set working directory
setwd("C:/Users/lledesma.TIMES/Documents/ONR/GnG_and_Nback_behavioral_data_preprocessing/Processed Data")

# Load in the GnG data
GnG.performance <- read.csv("GnG.trial.type.csv")

# Data cleaning- we are only interested in Day 1
GnG.performance <- GnG.performance %>% filter(Day.Type == "Day 1" & BlockName == "Colors and Shape") %>% select(-X)

# Load in the Nback data (Reacted)
Nback.reacted <- read.csv("Nback.target.reacted.csv")

# Data cleaning- we are only interested in Day 1
Nback.performance <- Nback.reacted %>% filter(Day.Type == "Day 1" & BlockName == "2-Back AR w ND") %>% select(-X)

# Set working directory
setwd("~/ONR/BRIEF")

# Load in the BRIEF data
Inhibtion.T.scores <- read.csv("Inhibition.T.scores.csv")
Working.Memory.T.scores <- read.csv("Working.Memory.T.scores.csv")

# Clean the BRIEF data
Inhibtion.T.scores <- Inhibtion.T.scores %>%
  select(ID, T.score)

Working.Memory.T.scores <- Working.Memory.T.scores %>%
  select(ID, T.score)  

# Adding demographic data
setwd("C:/Users/lledesma.TIMES/Documents/ONR/Demographics")

# Save the data as a CSV
demographics <- read.csv("complete.demographics.csv")

# Clean demographics
demographics <- demographics %>%
  select(-c(X, email))
```

### Merge the datasets together 

Here we will merge our datasets to include demographic information, the T-scores from the BRIEF scales, and our performance on Day 1 VR. 

```{r merge the datasets}
# merge the inhibition datasets
GnG.performance.merged <- GnG.performance %>%
  rename(ID = UserID) %>%
  merge(Inhibtion.T.scores, by = "ID") %>%
  merge(demographics, by = "ID")

# merge the working memory datasets
Nback.performance.merged <- Nback.performance %>%
  rename(ID = UserID) %>%
  merge(Working.Memory.T.scores, by = "ID")  %>%
  merge(demographics, by = "ID")

```

### Getting to know our data (Sample size, etc.)

Here is a description of our datasets for inhibition and working memory. Starting with inhibition we have 128 rows and 8 variables. Each participant has two rows worth of data, one that corresponds to performance on the Go trial and the other for the No-Go. The GnG version of BlockName chosen is 'Colors and Shapes,' which is the easiest condition that consists of no arrows- simply green cubes and some red cubes or green pyramids. Only data from Day 1 is present. Additionally, we have information on the total number of trials for each trial type, some demographic information, and our outcome variable which is that person's BRIEF inhibition T-score. The following code justifies that this is all true. 

This is similar for our working memory dataset. There are 128 rows with 8 variables. Each participant has two rows attributed to them. One for performance on the target trial (a shape that was presented two shapes ago) and a non-target trials (called distractor). Performance is not measured the same as it is for the inhibition dataset. In that dataset, performance is measured by the variable 'Correct', which represents correct trials with a score of 1 and incorrect trials with a score of 0. For the Nback, the variable 'Reacted' was used. This was done on purpose to remove any incorrect target trials because the participant did not hit in the same direction of the arrow. An added bonus is that since we chose the variable 'Reacted' the percentages in the Distractor rows are actually reporting the percentage of false alarms. This will become important later in our analysis. Each trial type has the number of trials for the session mentioned. Only one versions of the N-back is present. It is called '2 Back AR w ND' which means target trials have arrows on them and no distractors are present. Only data from Day 1 is in this dataset and lastly, our outcome variable BRIEF working memory T scores is included. 

One important thing to notice. For Go and No-Go trials, the program consistently has an 80/20 ratio. But for N-back there is a bit more variability as shown below. It is still roughly around 80/20. 

**Please be mindful:** The numbers reported above are from the information below. The information in the following code chunk is much more accurate since it is reactive to an increase in our sample size from on going data collection. Anything written not in the code chunk was written manually.  

```{r getting to know our data}
# Starting with the inhibition data
# This is what it looks like
GnG.performance.merged %>%
  head(10)  %>%
  kbl() %>%
  kable_paper(full_width = F)

# Missing data
GnG.missing.data <- GnG.performance.merged %>%
  select(-c(race, ethnicity)) %>%
  filter(!complete.cases(.))

paste("We have:",nrow(GnG.missing.data),"missing data for the inhibition dataset- not including demographic")

# The dimensions
dim(GnG.performance.merged)

# Testing day types present
unique(GnG.performance.merged$Day.Type)

# Types of GnG versions present
unique(GnG.performance.merged$BlockName)

# Types of stimuli present
unique(GnG.performance.merged$Trial.Type)

# Trial numbers per trial type
GnG.performance.merged %>%
  group_by(Trial.Type, trial.num) %>%
  count()

# Sample size
paste("Our sample size for the inhibition data is:", length(unique(GnG.performance.merged$ID)))

# Next with working memory data
# This is what it looks like
Nback.performance.merged %>%
  head(10)  %>%
  kbl() %>%
  kable_paper(full_width = F)

# Missing data
Nback.missing.data <- Nback.performance.merged %>%
  select(-c(race, ethnicity)) %>%
  filter(!complete.cases(.))

paste("We have:",nrow(Nback.missing.data),"missing data for the working memory dataset")

# The dimensions
dim(Nback.performance.merged)

# Testing day types present
unique(Nback.performance.merged$Day.Type)

# Types of GnG versions present
unique(Nback.performance.merged$BlockName)

# Types of stimuli present
unique(Nback.performance.merged$Trial.Type)

# Trial numbers per trial type
Nback.performance.merged %>%
  group_by(Trial.Type, trial.num) %>%
  count()

# Sample size
paste("Our sample size for the inhibition data is:", length(unique(Nback.performance.merged$ID)))


```


### Demographic information

It is always good to include some type of demographic information. It gives you an idea if the data might be biased and helps you figure out by how much you want to generalize your results. Here are some interesting results. Most of our sample consists of Asians and White people. One third of our sample is Hispanic. It is pretty split between Males and Females with the inclusion of one Intersex person. Lastly (but not surprisingly), our Age histogram is positively skewed, meaning that most of our sample are between 19-24 and there are fewer subjects that are older than that. 

```{r demographic information}
# Demographic information for inhibition data set
# Race
GnG.performance.merged$race %>% 
  table() %>%
  prop.table() %>%
  stack() %>%
  select(Race = ind, Proportion = values) %>%
  arrange(Proportion)

# Ethnicity
GnG.performance.merged$ethnicity %>% 
  table() %>%
  prop.table() %>%
  stack() %>%
  select(Ethnicity = ind, Proportion = values) %>%
  arrange(Proportion)

# Sex
GnG.performance.merged$Sex %>% 
  table() %>%
  prop.table() %>%
  stack() %>%
  select(Sex = ind, Proportion = values) %>%
  arrange(Proportion) %>%
  mutate(Proportion = round(Proportion,2))

# Age
hist(GnG.performance.merged$Age)

# Demographic information for working memory data set
Nback.performance.merged$race %>% 
  table() %>%
  prop.table() %>%
  stack() %>%
  select(Race = ind, Proportion = values) %>%
  arrange(Proportion)

# Ethnicity
Nback.performance.merged$ethnicity %>% 
  table() %>%
  prop.table() %>%
  stack() %>%
  select(Ethnicity = ind, Proportion = values) %>%
  arrange(Proportion)

# Sex
Nback.performance.merged$Sex %>% 
  table() %>%
  prop.table() %>%
  stack() %>%
  select(Sex = ind, Proportion = values) %>%
  arrange(Proportion) %>%
  mutate(Proportion = round(Proportion,2))

# Age
hist(Nback.performance.merged$Age)


```


### Loss of data

The merger resulted in 64 subjects with all the data that we are interested in. Below are ID's that were not able to be merged either because we did not have Day 1 GnG data or did not have their BRIEF T scores. Additionally, they may have this data, but some ID's were dropped in earlier processing scripts because they had duplicate ID's- meaning one subject was suppose to be ID X1 and the other X2 but both were named X1. Until the ID's can be assigned manually in Qualtrics both ID's like these would be dropped. 

```{r loss of data checker}
# IDs that have GnG performance
length(unique(GnG.performance$UserID))

# IDs that have BRIEF inhibition scores 
length(unique(Inhibtion.T.scores$ID))

# IDs that are in common
intersect(GnG.performance$UserID, Inhibtion.T.scores$ID)

# IDs that are in GnG and not in BRIEF
setdiff(GnG.performance$UserID, Inhibtion.T.scores$ID)

# IDs that are in BRIEF and not in GnG
setdiff(Inhibtion.T.scores$ID,GnG.performance$UserID)

```
Reasons for these discrepancies- data for the BRIEF started collection way after 100 subjects completed the VR tasks Additionally, the BRIEF is collected the very first day of testing while the baseline VR tasks are done on the next visit. Does the discrepancy above could show subjects that either dropped the study after their first visit or that have not yet completed their next visit. 


### Statistical Approach

In order to know whether there is a relationship between the BRIEF Self Report and our VR cognitive tasks, we will be using two separate analysis. 

The first analysis will take the Inhibition data and create groups based on performance on the No-Go trial. We will then see if there are significant differences between groups in T-scores of the BRIEF inhibition scale. Thus, we will be using a One-Way ANOVA with No-Go performance as our categorical predictor variable and BRIEF Inhibition T-scores as our dependent variable.

The second analysis will take the percentage of hit rate and false alarm rate in the Nback, convert them into Z-scores to normalize them, subtract one from the other to calculate d prime, and then run a simple regression between d prime outcome and T-scores from the BRIEF working memory scale. 

## Inhibition analysis

### Creating our groups

From visualizing our data below and obtaining the frequency of performance for all of our subjects. We can create potentially three groups. Group 1) No errors; Group 2) Relative few errors >= .9 but not 1; Group 3) Engaged in more errors than expected <.9

These numbers indicate the percentage of correct No-Go trials in the easiest GnG paradigm. 

```{r creating the groups}
# Remove the go trials
GnG.data <- GnG.performance.merged %>%
  filter(Trial.Type == "No-Go")

# Visualizing the data
GnG.data %>%
  ggplot(aes(x = trial.mean.correct)) +
  geom_histogram(fill = "white",
                 color = "black",
                 bins = 40) +
  scale_y_continuous(expand = c(0,0), limits = c(0,30)) + 
  theme_classic() +
  labs(x = "Proportion of correct No-Go Trials",
       y = "Frequency",
       caption = bquote(bold("Figure 1:") ~ "A histogram showing the spread of performance for No-Go trials.")) +
  theme(plot.title = element_text(size = 18,
                                  hjust = 0.5),
        axis.title = element_text(size = 12, face = "bold"),
        axis.text = element_text(size = 12),
        plot.caption = element_text(size = 13,
                                    hjust = 0))

# Create a table of performance for the No-Go trial
table(GnG.data$trial.mean.correct)


# We will use this information to create three groups
GnG.data <- GnG.data %>%
  mutate(Group = ifelse(trial.mean.correct == 1, "No Mistakes",
                        ifelse(trial.mean.correct >= .9, "Few Mistakes", "Many Mistakes")))

# Report the group size
GnG.data %>%
  group_by(Group) %>%
  count() %>%
  kbl() %>%
  kable_paper(full_width = F)
```


### Visualize our data

Let's create bar graphs to see what the mean of  T-scores look like between groups

```{r visualize our grouped data}
# Display a bar chart
GnG.data %>%
  mutate(Group = factor(Group,
         levels = c("No Mistakes", "Few Mistakes", "Many Mistakes"))) %>%
  ggplot(aes(x=Group, y = T.score)) +
  stat_summary(fun = "mean", 
               geom = "bar",
               width = .5,
               fill = "white",
               color = "black") +
  stat_summary(fun.data = mean_cl_boot,
               geom = "errorbar",
               width = .2,
               color = "black") +
  scale_y_continuous(expand = c(0,0), limits = c(0,90)) +
  theme_classic() +
  labs(title = "Inhibition T-scores between No-Go Performance Groups",
       x = "No-Go Performance Group",
       y = "Inhibition T-scores") +
  geom_jitter(width = .2,
              size = 1.5,
              color = "#6495ED") +
  theme_classic() +
  theme(plot.title = element_text(size = 18,
                                  hjust = 0.5),
        axis.title = element_text(size = 12, face = "bold"),
        axis.text = element_text(size = 12))



```


### Run a One-way ANOVA

Now we will run an ANOVA to then visualize the spread of the residuals. I am adding covariates, idk if this is still called a one-way ANOVA or not due to it. 

```{r run an ANOVA}
# Run an ANOVA
aov.model <- aov(T.score ~ Group + Sex + Age, data = GnG.data)

# Obtain the summary of the model
summary(aov.model)


# Run an interaction ANOVA
aov.model.int <- aov(T.score ~  Sex + Group:Age, data = GnG.data)

# Obtain the summary of the model
summary(aov.model.int)

```

It seems that the only thing here that was significant is Age, which indicates that Age significantly explains some of the variables of our BRIEF inhibition T-score. 

### Plot the residuals

```{r plotting the residuals of our GnG data, out.width = "100%"}
# Add standardized residuals to our data frame
GnG.data$standardized.residuals <- rstandard(aov.model)

# Add fitted values to our data frame
GnG.data$fitted.values <- aov.model$fitted.values

# Create a graph using the fitted values and the standardized residuals 
plot.1 <- GnG.data %>%
  ggplot(aes(x = fitted.values, y=standardized.residuals)) +
  geom_point() +
  theme_classic() +
  labs(title = "Residuals vs Fitted",
       x = "Fitted Values",
       y = "Standardized Residuals",
       caption = "aov(T.score ~ Group)") +
  theme(plot.title = element_text(size = 14,
                                  hjust= .5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10),
        plot.caption = element_text(size = 10,
                                    hjust = .5))

# Create a Q-Q Plot
plot.2 <- GnG.data %>%
  ggplot(aes(sample= standardized.residuals)) +
  geom_qq() +
  stat_qq_line() +
  theme_classic() +
  labs(title = "Normal Q-Q Residuals",
       x = "Theoretical Quantiles", 
       y = "Standardized Residuals",  
       caption = "aov(T.score ~ Group)") +
  theme(plot.title = element_text(size = 14,
                                  hjust= .5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10),
        plot.caption = element_text(size = 10,
                                    hjust = .5))

# Show the plots
ggarrange(plot.1, plot.2)


```
Since ANOVAS are robust, the following assumptions from above look okay.


### ANOVA Conclusion

Since overall our data looks good, we can take the results from the ANOVA at face value. Overall our one-way ANOVA (?tbh this might be an ANCOVA but idk lol) showed no statistical difference in BRIEF Inhibition T scores between No-Go Performance Groups F(2,58)= 0.766, p > .05. However, Age was shown to be significant F(1,58)= 5.299 p < .05 in explaining inhibition T-score variability. 


### Plotting Age and Inhibition T-scores

```{r plotting Age and Inhibition T scores}
# Create a scatterplot
GnG.data %>%
  ggplot(aes(x = Age, y = T.score)) +
  geom_point() +
  geom_smooth(method = "lm") +
  theme_bw() +
  labs(title = "Scatterplot of Age and Inhibition T-score",
       x = "Age",
       y = "Inhibition T-score") +
  theme(plot.title = element_text(size = 15,
                                  hjust = 0.5),
        axis.title = element_text(size = 12, face = "bold"),
        axis.text = element_text(size = 12)) 


```

This makes a lot of sense. A higher T-score indicates more impulsivity. Here we can see that typically as our participants are older they are less likely to engage in impulsive behaviors. 


## Working Memory analysis

### Calculating d prime

Our goal is to redefine our outcome variable, which is now Nback performance overall by taking into account performance from both Target trials and Distractor trials. A great way to do this is by calculating d prime, which takes into account performance from both trial types and producing a score where a higher d prime indicates better performance in both trial types and a lower d prime corresponds with someone that did poorer in both trial types. 

Why use d prime? Initially I scored working memory as performance on the Target trial, aka how well they did on the trial where a shape being presented matched that of a shape shown two items back. There is an issue with this technique, which is that in theory, someone could be hitting a lot of shapes randomly, which will increase their chances of scoring higher on the target trials. Additionally, including performance on the non-target trials can act as a tie breaker, because we could have two people with the same target trial scores, but one had a lot less false alarms than the other, thus they should get credit for that. By calculating d prime, all of these issues get resolved and I think has more validity to it. 

So basically, a higher d prime means better performance on both Target and Non-target trials. So with this knowledge, we would predict that people with higher working memory T-scores (more problems with their working memory) the lower their d prime score. 

```{r converting our hit and false alarm rates into z scores}
# transform the data into wide
Nback.data.wide <- Nback.performance.merged %>%
  select(-c(trial.num)) %>%
  pivot_wider(names_from = Trial.Type, values_from = target.mean.reacted) %>%
  rename(Hit.rate = Target, False.Alarm.Rate = Distractor)

# View the range of scales for the target performance
Nback.data.wide$Hit.rate %>% sort()

# Modify the zeroes in this vector by making them not zero but still less than the next smallest score
Nback.data.wide <- Nback.data.wide %>%
  mutate(Hit.rate = ifelse(Hit.rate == 0, .02, Hit.rate))

# Quality check
Nback.data.wide$Hit.rate %>% sort()

# View the range of scales for the distractor performance - it checks out
Nback.data.wide$False.Alarm.Rate %>% sort()


# Convert the hit and false rate into z scores
Nback.data.wide <- Nback.data.wide %>%
  transmute(ID,
            Age,
            Sex,
            T.score,
            Hit.rate,
            Hit.rate.mean = mean(Hit.rate),
            Hit.rate.sd = sd(Hit.rate),
            Hit.rate.z = (Hit.rate - Hit.rate.mean)/Hit.rate.sd,
            False.Alarm.Rate,
            False.Alarm.Rate.mean = mean(False.Alarm.Rate),
            False.Alarm.Rate.sd = sd(False.Alarm.Rate),
            False.Alarm.Rate.z = (False.Alarm.Rate - False.Alarm.Rate.mean)/False.Alarm.Rate.sd,
            d.prime = Hit.rate.z - False.Alarm.Rate.z)

# Some minor data cleaning
Nback.dprime <- Nback.data.wide %>%
  select(ID, Age, Sex, Hit.rate, False.Alarm.Rate, d.prime, T.score)

```


### Visualize our data


```{r create a scatterplot}
# Create a scatterplot
Nback.dprime %>%
  ggplot(aes(x = T.score, y = d.prime)) +
  geom_point() +
  geom_smooth(method = "lm") +
  theme_bw() +
  labs(title = "Scatterplot of Inhibition T Scores and Nback Trial Type d.prime",
       x = "Inhibition T Scores",
       y = "d.prime") +
  theme(plot.title = element_text(size = 15,
                                  hjust = 0.5),
        axis.title = element_text(size = 12, face = "bold"),
        axis.text = element_text(size = 12))


```


### Running a regression

```{r running a simple regression}
# Running a simple regression
regression.model <- lm(d.prime ~ T.score + Age + Sex, data= Nback.dprime)

# Obtain a summary of the model
summary(regression.model)
```
We can see here that nothing was significant :(

### Plot the residuals

```{r plotting the residuals of our Nback data}
# Add standardized residuals to our data frame
Nback.dprime$standardized.residuals <- rstandard(regression.model)

# Add fitted values to our data frame
Nback.dprime$fitted.values <- regression.model$fitted.values

# Create a graph using the fitted values and the standardized residuals 
Nback.dprime %>%
  ggplot(aes(x = fitted.values, y=standardized.residuals)) +
  geom_point() +
  geom_smooth(method = "lm", color = "black") +
  theme_bw() +
  labs(title = "Standardized Residuals vs Fitted Values ",
       x = "Fitted Values",
       y = "Standardized Residuals",
       caption = "lm(d.prime ~ T.score)") +
  theme(plot.title = element_text(size = 15,
                                  hjust = 0.5),
        axis.title = element_text(size = 12, face = "bold"),
        axis.text = element_text(size = 12),
        plot.caption = element_text(size = 12))


```


