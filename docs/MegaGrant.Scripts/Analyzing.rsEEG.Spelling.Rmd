---
title: "Analyzing resting-state EEG and Spelling Performance in Young Adults"
author: "Leandro Ledesma"
date: "2024-03-13"
output: html_document
---

### Universal block code settings

```{r setup}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(comment = NULL)

```

### Load in the data manipulation packages first

```{r loading in the packages, warning = FALSE}
library(tidyverse)
library(ggplot2)
library(ggpubr)
library(readxl)
library(kableExtra)
library(stringdist)
library(rempsyc) # Create APA tables with nice_table()
library(flextable) # Adds aesthetic functions to the table from above
library(broom) # Converts regression outputs into dataframes using the tidy() function

```

### Load in our predictor variable

We will be loading in the scored version of the ARFA- specifically the spelling portion of it. However, two different approaches were used for the scoring of spelling performance- that is why two datasets are being imported. 

Additionally, we are gonna do some data cleaning and transform the spelling performance to spelling errors. 

```{r load in predictor variable, warning= FALSE}
# Set the working directory
setwd("~/Masters Project/cleaned_predictor_covariates")

# Load in the ARFA performance measures
ARFA1 <- read.csv("ARFA.Spelling.Tweaked.Scored.csv")

# Add Spelling ERror Variable
ARFA1 <- ARFA1 %>%
  mutate(Spelling_Error = max(Spelling_Performance) - Spelling_Performance)

```


### Load in our dependent variable

We have the power of 5 frequency bands for each subject that were averaged across the scalp (No.Topography) and for each topographical domain (Topography). The analysis below will choose the former as the dependent variable since each subject potentially has a single score for a dependent variable instead of 5. However for future analysis- I may create another analysis that takes topography into account. 

```{r load in dependent variable, warning = FALSE}
# Set the working directory
setwd("~/Masters Project/cleaned_dependent_variable")

# Load in the rsEEG datasets
rsEEG1 <- read.csv("Frequency.Bands.No.Topography.csv")

rsEEG2 <- read.csv("Frequency.Bands.Topography.csv")

```



## Picking the best combination of variables

The variables we have selected to analyze, both the predictor and outcome variable, can be scored or represented in many different ways. 

In terms of our **predictor variable**- the ARFA, there were two different approaches taken to measure Spelling Performance. The first was to take the recommendations of the ARFA instructions by giving all subjects a 2, 1, or 0 for each item and then adding them all up to get a raw score. The second was using an approach to investigate spelling errors, which was operationalized with Levenshtein Distance. This output was highly skewed so a log transformation was used. 

For our **outcome variable**, which is the power of different frequency bands calculated from fast Fourier transform, we have decided for now to use data that was averaged across the scalp. This was done to make the analysis more simpler but this can be changed later in future analysis. Additionally, we are restricting our analysis to delta and theta frequency bands (slower frequency bands), since this is what the literature tends to report on.

## What does the literature say?

A detailed explanation is currently being written on my [Wiki Page](https://github.com/LeoLedesma237/LeoWebsite/wiki/My-Master's). It is nothing too fancy- just briefly summarizes findings of several different studies. Many studies have investigated rsEEG biomarkers in children that are poor spellers or have dyslexia. While there is some overlap between children with dyslexia and poor spellers, both are different populations. Thus results from both groups needs to be carefully considered instead of being lumped together. While there are some inconsistencies in the literature, which many are nicely explained in Lui and colleagues (2021) study, for the most part, it seems that children who are poor spellers and children with dyslexia tend to have higher delta and theta power than children who are good spellers/do not have dyslexia. With this in mind- this will temporarily be used to develop our hypotheses as a starting step. (At least this should be enough for Brown Bag). Will eventually go back to further investigate the literature more thoroughly.  

### Hypotheses

1. Poorer spelling performance is associated with elevated power for lower frequency bands (delta and theta).

1. Poorer spelling performace is 


The logic behind this is that poor spelling might be a sign of a less mature brain, which is represented by higher power of slower frequency bands (delta and theta). With this in mind, it is crucial then to introduce Age as a covariate into our analysis. 


### What is the novelty in this?

I mentioned above the results I found from papers that investigate this in children. Most of which have small sample sizes (I think- I need to recheck this to confirm). However, we have a sample of mostly young adults. It ranges from 15 to 25 years. Also, we have data from more than 400 subjects. These types of EEG studies are rarely reported, so it is nice that we have such a large sample size. 


### Data set 1: Original ARFA Spelling Performance vs rsEEG with no topography information

We see that we have 430 unique ID's in this dataset. Let's also visualize our predictor and outcome variable through a scatterplot to see if we see any type of linear relationship. 

```{r combine the datasets 1, out.width= "90%"}
# Combine the the datasets by using the left_join function
data1 <- ARFA1 %>%
  left_join(rsEEG1, by = "ID") %>%
  filter(complete.cases(.))

# Get the dimensions of the dataset
dim(data1)

# How many unique ID's are present
length(unique(data1$ID))

# Visualize the data
plot1 <- data1 %>%
  ggplot(aes(x = Spelling_Error, y = delta)) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(title = "ARFA Spelling Error and\nDelta Power",
       x = "Spelling Error") +
  theme_classic() +
    theme(plot.title = element_text(size = 16,
                                  hjust = 0.5),
        axis.title = element_text(size = 12, face = "bold"),
        axis.text = element_text(size = 12),
        plot.caption = element_text(size = 13,
                                    hjust = 0))

plot2 <- data1 %>%
  ggplot(aes(x = Spelling_Error, y = theta)) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(title = "ARFA Spelling Error and\nTheta Power",
       x = "Spelling Error") +
  theme_classic() +
    theme(plot.title = element_text(size = 16,
                                  hjust = 0.5),
        axis.title = element_text(size = 12, face = "bold"),
        axis.text = element_text(size = 12),
        plot.caption = element_text(size = 13,
                                    hjust = 0))

ggarrange(plot1, plot2)


# Visualize the data
plot3 <- data1 %>%
  ggplot(aes(x = Spelling_Error, y = alpha)) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(title = "ARFA Spelling Error and\nAlpha Power",
       x = "Spelling Error") +
  theme_classic() +
    theme(plot.title = element_text(size = 16,
                                  hjust = 0.5),
        axis.title = element_text(size = 12, face = "bold"),
        axis.text = element_text(size = 12),
        plot.caption = element_text(size = 13,
                                    hjust = 0))

plot4 <- data1 %>%
  ggplot(aes(x = Spelling_Error, y = beta)) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(title = "ARFA Spelling Error and\nBeta Power",
       x = "Spelling Error") +
  theme_classic() +
    theme(plot.title = element_text(size = 16,
                                  hjust = 0.5),
        axis.title = element_text(size = 12, face = "bold"),
        axis.text = element_text(size = 12),
        plot.caption = element_text(size = 13,
                                    hjust = 0))

ggarrange(plot3, plot4)

```



### Conclusions from data visualizations

What we found is consistent with the logic we developed from reports in the literature that investigate this in children (what a relief). As mentioned, we are predicting that poorer performers in a spelling task will have higher power for slower frequency bands (delta and theta). As we can see from the first two graphs, the worse a subject performed on the spelling task the higher the power they tended to have for both delta and theta frequency bands. Additionally, when looking at the log of spelling errors, we see that this looks positively associated with delta and theta power, which also makes sense with the findings in the literature.

Knowing that we are probably on the right track- let's continue with the analysis. 



### Data Analysis (Simple Regression)

Let's start by running a simple regression to see how well the models perform. We will construct four models. These models will not make up our final results. It is more for us to understand our data better. There will be different n sizes depending on the Predictor variable type chosen (Spelling performance vs Spelling Errors). 

model1: Delta ~ ARFA Spelling Performance

model2: Theta ~ ARFA Spelling Performance

model2: Delta ~ ARFA Spelling Errors

model4: Theta ~ ARFA Spelling Errors

It seems that the log transformation of the Spelling Errors (model 3 and model 4) explained slightly more of the variance (but like by barely) than the Original way of scoring it (model 1 and model 2). 

```{r running a simple regression}
# Create the first two simple regressions using the Spelling Performance predictor
simple.regression1.delta <- lm(delta~Spelling_Error, data1)
simple.regression1.theta <- lm(theta~Spelling_Error, data1)
simple.regression1.alpha <- lm(delta~Spelling_Error, data1)
simple.regression1.beta <- lm(theta~Spelling_Error, data1)


# Check their performance
summary(simple.regression1.delta)
summary(simple.regression1.theta)
summary(simple.regression1.beta)
summary(simple.regression1.alpha)

```

### Adding covariates

Now that our predictor variables look somewhat promising- we need to add in several covariates that are also likely to influence our outcome variable (rsEEG power for delta and theta). From my experience as a researcher, it is very common and expected to introduce age and sex as covariates into the analysis. I don't think that sex will lead to anything, but it is still worth introducing. Age on the otherhand is crucial since it is likely to play a significant in explaining the variance of delta and theta power. Again this would go back to the idea of brain maturation.  

We will also introduce two additional covariates that are likely to play a role. The first is a measure of non-verbal IQ from the Cultural Fair Intelligence Test (CFIT). There are papers showing that power in resting-state EEG is related to IQ. I don't think it applies to slower frequency bands like delta and theta but it is still worth looking into. We do not have the IQ scores per se, but instead their raw scores of correct responses, so this is what we will be using. The second covariate is a measure of the person's upbringing. In the initial grant of the MegaGrant study, the research question was based on investigating differences between subjects (that are now adults) that were raised in orphanages vs those raised by biological families. This dichotomous grouping variable is called group and will be introduced into our analysis. 

Thus, our potential final models will include our predictor variable, four covariates and our outcome variable (delta and theta separetly).

```{r loading in covariates, warning = FALSE}
# Set working directory for demographic and group data
setwd("~/Masters Project")

# load in demographic information
demo <- read_excel("MegaGrant_TBL_.xlsx")

# data cleaning
demo <- demo %>%
  select(ID, Sex, Age, Group) %>%
  mutate(ID = as.numeric(ID),
         Age = as.numeric(Age))

# Set working directory for CFIT data
setwd("~/Masters Project/cleaned_predictor_covariates")

# Load in the CFIT data
CFIT <- read.csv("CFIT.scores.csv")
```


### Introduce covariates into our data frames

```{r introduce the covaraites}
# Introduce the covariates for data1
final.data1 <- data1 %>%
  left_join(demo, by ="ID") %>%
  left_join(CFIT, by = "ID")


# Remove any subjects with missing data
final.data1 <- final.data1 %>%
  filter(complete.cases(.))

# Table on continuous predictors
continuous <- final.data1 %>%
  select(Spelling_Error,
         Raw.Score,
         Age)

# We nee to have our continuous variables in one column
continuous.long <- continuous %>%
  stack() %>%
  select(Predictors = ind,
         values = values)

# Obtain the descriptive statistics from the long format demographic sheet
continuous.summarize <- continuous.long %>%
  group_by(Predictors) %>%
  summarize(Mean = round(mean(values),2),
            Med. = round(median(values),2),
            SD = round(sd(values),2),
            Min. = min(values),
            Max. = max(values),
            N = nrow(continuous))

# Table cleaning
continuous.summarize <- continuous.summarize %>%
  mutate(Predictors = factor(Predictors, 
                             labels = c("Spelling Error", 
                                        "CFIT Raw Score",
                                        "Age")))


# Create an APA style table with the results
continuous.summarize %>%
  nice_table(title = "Descriptive Statistics of Continuous Predictors") %>%
  bold(part = "header")

# Create a table for continuous variables
sex.df <- data.frame(table(final.data1$Sex)) %>%
  pivot_wider(names_from = Var1, values_from = Freq) %>%
  mutate(N = `F` + M) %>%
  mutate(Percent = round(M/N,2)*100) %>%
  select(-`F`, Frequency = M, Percent, N)

group.df <- data.frame(table(final.data1$Group)) %>%
  pivot_wider(names_from = Var1, values_from = Freq) %>%
  mutate(N = BF + IC) %>%
  mutate(Percent = round(BF/N,2)*100) %>%
  select(-IC, Frequency = BF, Percent, N)

# Stack the tables
categorical.df <- rbind(sex.df,
                        group.df) %>%
  mutate(`_` = c("Male", "BF")) %>%
  select(`_`, Frequency, Percent, N)

# Create an APA style table with the results
categorical.df %>%
  nice_table(title = "Descriptive Statistics of Categorical Predictors") %>%
  bold(part = "header")


```


### Creating a table for EEG power descriptive statistics

```{r create a table for EEG power descriptive statistics}
# Let's create a table fo the descriptive statistics
# Let's copy a paper to do this
EEG.data <- final.data1 %>%
  select(ID, delta, theta, alpha, beta, gamma) %>%
  pivot_longer(-ID, names_to = "Frequency_Band", values_to = "Power")


EEG.summarized <- EEG.data %>%
  group_by(Frequency_Band) %>%
  summarize(Mean = round(mean(Power),2),
            Med. = round(median(Power),2),
            SD = round(sd(Power),2),
            Min. = min(Power),
            Max. = max(Power),
            N = nrow(final.data1)) %>%
  mutate(order = c(3,4,1,5,2)) %>%
  mutate(Frequency_Band = factor(Frequency_Band,
                                 levels = c("delta",
                                            "theta",
                                            "alpha",
                                            "beta",
                                            "gamma"),
                                 labels = c("delta (0.5-4Hz)",
                                            "theta (4-8Hz)",
                                            "alpha (8-12Hz)",
                                            "beta (12-30Hz)",
                                            "gamma (30-40Hz)"))) %>%
  arrange(order) %>%
  select(-order)

# Create an APA style table with the results
EEG.summarized %>%
  nice_table(title = "Descriptive Statistics of Frequency Band Power") %>%
  bold(part = "header")



```


### Visualize our predictors

```{r visualize predictors, out.width = "50%"}
# We need to visualize predictors just to make sure assumptions are not being violated
final.data1 %>%
  ggplot(aes(x = Spelling_Error)) +
  geom_histogram(fill = "white",
                 color = "black",
                 bins = 20) +
  labs(x = "Spelling Errors") +
    theme(plot.title = element_text(size = 18,
                                  hjust = 0.5),
        axis.title = element_text(size = 18, face = "bold"),
        axis.text = element_text(size = 18),
        plot.caption = element_text(size = 18,
                                    hjust = 0))

final.data1 %>%
  ggplot(aes(x = Raw.Score)) +
  geom_histogram(fill = "white",
                 color = "black" ) +
  labs(x = "IQ Raw Scores") +
    theme(plot.title = element_text(size = 18,
                                  hjust = 0.5),
        axis.title = element_text(size = 18, face = "bold"),
        axis.text = element_text(size = 18),
        plot.caption = element_text(size = 18,
                                    hjust = 0))

final.data1 %>%
  ggplot(aes(x = Age)) +
  geom_histogram(fill = "white",
                 color = "black",
                 bins = 20) +
  labs(x = "Age") +
    theme(plot.title = element_text(size = 18,
                                  hjust = 0.5),
        axis.title = element_text(size = 18, face = "bold"),
        axis.text = element_text(size = 18),
        plot.caption = element_text(size = 18,
                                    hjust = 0))
```


### Visualizing Outcomes

```{r visualizing outcome variables, out.width = "50%"}
# We need to visualize our outcomes just to make sure they are normally distributed
final.data1 %>%
  ggplot(aes(x = delta)) +
  geom_histogram(fill = "white",
                 color = "black" ) +
  labs(x = "delta power") +
    theme(plot.title = element_text(size = 18,
                                  hjust = 0.5),
        axis.title = element_text(size = 18, face = "bold"),
        axis.text = element_text(size = 18),
        plot.caption = element_text(size = 18,
                                    hjust = 0))

final.data1 %>%
  ggplot(aes(x = theta)) +
  geom_histogram(fill = "white",
                 color = "black" ) +
  labs(x = "theta power") +
    theme(plot.title = element_text(size = 18,
                                  hjust = 0.5),
        axis.title = element_text(size = 18, face = "bold"),
        axis.text = element_text(size = 18),
        plot.caption = element_text(size = 18,
                                    hjust = 0))




```



### Run a multiple regression

It seems that the model that used Levenshtein distance as a measure of Spelling Performance (model2; it calculated spelling errors and was log transformed) slightly outperformed the model that used the original/intended way of scoring Spelling Performance (model 1). Thus we will be using model 2 for post assumption tests and data visualization (this will also keep the document less cluttered with information). In all honestly it doesn't matter cause in neither model was our predictor significant. 

The results from model 2 show that the log of spelling error was not significantly related to delta nor theta power. However, the covariate age and sex was significant. 

```{r run a multiple regression}
# Create the models
model1.delta <- lm(delta ~ Spelling_Error + Sex + Age + Group + Raw.Score, data = final.data1)
model1.theta <- lm(theta ~ Spelling_Error + Sex + Age + Group + Raw.Score, data = final.data1)


model2.delta <- lm(delta~ Spelling_Error + Age + Spelling_Error*Age , data = final.data1)
model2.theta <- lm(theta~ Spelling_Error + Age + Spelling_Error*Age , data = final.data1)

# Obtain the summaries of model 1
summary(model1.delta)
summary(model1.theta)


summary(model2.delta)
summary(model2.theta)

```


## Making the results prettier

```{r making the results prettier}
detach("package:flextable", unload=TRUE)

# Convert our first model into a dataframe
model1.delta.df <- broom::tidy(model1.delta) 

# Keeping only three values for each variable
model1.delta.df.rounded <- model1.delta.df %>%
  mutate(across(where(is.numeric), ~ round(., 4))) %>%
  arrange(p.value)

# Adding astricks
model1.delta.df.astericks <- model1.delta.df.rounded %>%
  mutate(p.value = case_when(
           p.value < .001 ~ paste(format(p.value),"***",sep=""),
           p.value < .01 ~  paste(format(p.value),"**",sep=""),
           p.value < .05 ~  paste(format(p.value),"*",sep=""),
           TRUE ~ as.character(p.value)
         ))


# Print to check the cleaning
model1.delta.df.astericks %>%
  kbl(caption = "Multiple regression model for delta") %>%
  kable_classic(full_width = F, html_font = "Cambria") %>%
  footnote(general  = c("Residual standard error: 0.2227 on 445 degrees of freedom", 
                        "Multiple R-squared:  0.2583,	Adjusted R-squared:   0.25",
                        "F-statistic:    31 on 5 and 445 DF,  p-value: < 2.2e-16"))


# Convert our second model into a dataframe
model1.theta.df <- broom::tidy(model1.theta) 

# Keeping only three values for each variable
model1.theta.df.rounded <- model1.theta.df %>%
  mutate(across(where(is.numeric), ~ round(., 4))) %>%
  arrange(p.value)

# Adding astricks
model1.theta.df.astericks <- model1.theta.df.rounded %>%
  mutate(p.value = case_when(
           p.value < .001 ~ paste(format(p.value),"***",sep=""),
           p.value < .01 ~  paste(format(p.value),"**",sep=""),
           p.value < .05 ~  paste(format(p.value),"*",sep=""),
           TRUE ~ as.character(p.value)
         ))


# Print to check the cleaning
model1.theta.df.astericks %>%
  kbl(caption = "Multiple regression model for theta") %>%
  kable_classic(full_width = F, html_font = "Cambria") %>%
  footnote(general  = c("Residual standard error: 0.1812 on 445 degrees of freedom",
                        "Multiple R-squared:  0.09394,	Adjusted R-squared:  0.08376",
                        "F-statistic: 9.227 on 5 and 445 DF,  p-value: 2.269e-08"))


# Convert our second model into a dataframe
model2.delta.df <- broom::tidy(model2.delta) 

# Keeping only three values for each variable
model2.delta.df.rounded <- model2.delta.df %>%
  mutate(across(where(is.numeric), ~ round(., 4))) %>%
  arrange(p.value)

# Adding astricks
model2.delta.df.astericks <- model2.delta.df.rounded %>%
  mutate(p.value = case_when(
           p.value < .001 ~ paste(format(p.value),"***",sep=""),
           p.value < .01 ~  paste(format(p.value),"**",sep=""),
           p.value < .05 ~  paste(format(p.value),"*",sep=""),
           TRUE ~ as.character(p.value)
         ))


# Print to check the cleaning
model2.delta.df.astericks %>%
  kbl(caption = "Multiple regression interaction model for delta") %>%
  kable_classic(full_width = F, html_font = "Cambria") %>%
  footnote(general  = c("Residual standard error: 0.1809 on 447 degrees of freedom",
                        "Multiple R-squared:  0.09321,	Adjusted R-squared:  0.08712", 
                        "F-statistic: 15.32 on 3 and 447 DF,  p-value: 1.677e-09"))

# Convert our second model into a dataframe
model2.theta.df <- broom::tidy(model2.theta) 

# Keeping only three values for each variable
model2.theta.df.rounded <- model2.theta.df %>%
  mutate(across(where(is.numeric), ~ round(., 4))) %>%
  arrange(p.value)

# Adding astricks
model2.theta.df.astericks <- model2.theta.df.rounded %>%
  mutate(p.value = case_when(
           p.value < .001 ~ paste(format(p.value),"***",sep=""),
           p.value < .01 ~  paste(format(p.value),"**",sep=""),
           p.value < .05 ~  paste(format(p.value),"*",sep=""),
           TRUE ~ as.character(p.value)
         ))


# Print to check the cleaning
model2.theta.df.astericks %>%
  kbl(caption = "Multiple regression interaction model for theta") %>%
  kable_classic(full_width = F, html_font = "Cambria") %>%
  footnote(general  = c("Residual standard error: 0.1762 on 416 degrees of freedom",
                        "Multiple R-squared:  0.08947,	Adjusted R-squared:  0.0829",
                        "F-statistic: 13.63 on 3 and 416 DF,  p-value: 1.704e-08",
                        "*** indicates p <.001", "** indicates p <.01 ","* indicates p <.05"))
```


### Visualizing the interaction effect

```{r visualizing the interaction}

final.data1 %>%
  ggplot(aes(x = Spelling_Error, y = delta)) +
  geom_point() +
  geom_smooth(method = "lm")

final.data1 %>%
  ggplot(aes(x = Age, y = delta)) +
  geom_point() +
  geom_smooth(method = "lm")



library(interactions)
interact_plot(model = model2.delta, pred = Spelling_Error, modx = Age)
interact_plot(model = model2.theta, pred = Spelling_Error, modx = Age)

```


### Visualizing significant covariates effect on rsEEG power

It looks like age is negatively correlated with theta power. Showing that as someone's brain matures there is lower production of theta power. This aligns with what some studies have reported in the literature. Additionally, graphed gender since it was shown to be significant but visually it doesn't really look like it is. 

```{r investigate Age}
# Save Age effect on delta from model 2
covariat.plot1 <- final.data1 %>%
  ggplot(aes(x = Age, y = delta)) +
  geom_point() +
  geom_smooth(method = "lm") +
  theme_classic()

# Save Age effect on theta from model 2
covariat.plot2 <- final.data1 %>%
  ggplot(aes(x = Age, y = theta)) +
  geom_point() +
  geom_smooth(method = "lm") +
  theme_classic()

ggarrange(covariat.plot1, covariat.plot2)


# Save Age effect on delta from model 2
covariat.plot1 <- final.data1 %>%
  ggplot(aes(x = Age, y = Spelling_Error)) +
  geom_point() +
  geom_smooth(method = "lm") +
  theme_classic()

# Save Age effect on theta from model 2
covariat.plot2 <- final.data1 %>%
  ggplot(aes(x = Age, y = Spelling_Error)) +
  geom_point() +
  geom_smooth(method = "lm") +
  theme_classic()

ggarrange(covariat.plot1, covariat.plot2)

### Visualize this as a boxplot
final.data1 <- final.data1 %>%
  mutate(Age.Quantile = ecdf(Age)(Age),
         Age.Group = ifelse(Age.Quantile > .66, "upper", 
                            ifelse(Age.Quantile >.33, "middle",
                                   "lower")))

# Create a box plot
final.data1 %>%
  ggplot(aes(x= Age.Group, y = Spelling_Error)) +
  geom_boxplot() +
  theme_classic() +
  labs(title = "Spelling Error by Age Quantiles",
       x = "Quantile Groups of Age",
       y = "Spelling Error") +
      theme(plot.title = element_text(size = 16,
                                  hjust = 0.5),
        axis.title = element_text(size = 12, face = "bold"),
        axis.text = element_text(size = 12),
        plot.caption = element_text(size = 13,
                                    hjust = 0))
  
```


### Residual distribution in the models (Post-estimation technique)

We need to plot the residuals for model2 (there are two of them) to see if they are normally distributed. It seems like it is skewed for both models. The first two plots are from the model predicting delta. The bottom two plots are from the model predicting theta. 

```{r plot the residuals for both models}
# introduce the residuals into the datasets
final.data1$studentized.residuals.delta <- rstudent(model2.delta)

# Create a histogram of the outcome variable
residual.plot1 <- final.data1 %>%
  ggplot(aes(x = studentized.residuals.delta)) +
  geom_histogram(fill = "white",
                 color = "black",
                 bins = 15) +
  scale_y_continuous(expand = c(0,0), limits = c(0,120)) + 
  theme_classic() +
  labs(title = "A histogram of Studentized Residuals",
       x = "Studentized Residuals",
       y = "Frequency",
       caption = bquote(bold("Figure 1:") ~ "A histogram of Studentized Residuals.")) +
  theme(plot.title = element_text(size = 11,
                                  hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10),
        plot.caption = element_text(size = 8,
                                    hjust = 0))

# Create a QQ plot
residual.plot2 <- final.data1 %>%
  ggplot(aes(sample= studentized.residuals.delta)) +
  geom_qq() +
  stat_qq_line() +
  theme_classic() +
  labs(title = "QQ Plot for predicting delta",
       x = "Theoretical Quantiles",
       y = "Frequency",
       caption = bquote(bold("Figure 2:") ~ "A QQ Plot of studentized residuals and theoretical quantiles.")) +
  theme(plot.title = element_text(size = 11,
                                  hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10),
        plot.caption = element_text(size = 8,
                                    hjust = 0))

# Plot the graphs
ggarrange(residual.plot1, residual.plot2)


```

### Conclusion

It seems that the residuals of our multiple regression are not normally distributed. This violation makes it difficult to generalize our findings. Additionally, it looks like our residuals are skewed/curved. Does this mean that we should use something else instead of a regression since there is a curvature? 


### What to do next

Aside from figuring out what I should do in terms of a robust approach since assumptions were violated- I also need to do the following:

- read more on what people are doing in adults studies that investigate this (ik ML is involved)
- read more on how topography might be invovled and why!
- keep an eye out for other theories- as in I used brain maturation but there could be other explanations
- read up on brain maturation? What is it? How can it be measured? What about other neuroimaging techniques?
- read up more on what rsEEG is, as in the values of FFT aka power (Mike cohen's book)
- start writing up a paper or a power point presentation with all of this information
- spend time reviewing the methods, like the assessments used, and the cleaning process of the EEG.


